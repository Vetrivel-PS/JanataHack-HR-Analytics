{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umairansari\\Desktop\\comp data\\analytics vidya\\janata hack\n"
     ]
    }
   ],
   "source": [
    "path='C:\\\\Users\\\\umairansari\\\\Desktop\\\\comp data\\\\analytics vidya\\\\janata hack'\n",
    "import os\n",
    "os.chdir(path)\n",
    "print(os.getcwd())\n",
    "import pandas as pd\n",
    "pd.set_option('use_inf_as_na', True)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "os.listdir()\n",
    "# from bayes_opt import BayesianOptimization\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier,StackingRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "#from imblearn.over_sampling import SMOTE \n",
    "import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "import gc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression,LinearRegression\n",
    "from sklearn.tree import DecisionTreeClassifier,ExtraTreeClassifier,ExtraTreeRegressor,DecisionTreeRegressor\n",
    "from sklearn.ensemble import AdaBoostClassifier,RandomForestClassifier,GradientBoostingClassifier\n",
    "from xgboost import XGBRFClassifier,XGBRFRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier,RidgeClassifierCV,SGDClassifier,ElasticNetCV\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained=pd.read_csv(\"train_jqd04QH.csv\")\n",
    "test=pd.read_csv(\"test_KaymcHn.csv\")\n",
    "trained[\"flag\"]=\"train\"\n",
    "test[\"flag\"]=\"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>training_hours</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>18359.000000</td>\n",
       "      <td>18359.000000</td>\n",
       "      <td>18359.000000</td>\n",
       "      <td>18359.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>16729.360096</td>\n",
       "      <td>0.847140</td>\n",
       "      <td>65.899014</td>\n",
       "      <td>0.132088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>9643.749725</td>\n",
       "      <td>0.110189</td>\n",
       "      <td>60.885300</td>\n",
       "      <td>0.338595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.448000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>8378.500000</td>\n",
       "      <td>0.796000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>16706.000000</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>25148.500000</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>89.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>33380.000000</td>\n",
       "      <td>0.949000</td>\n",
       "      <td>336.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        enrollee_id  city_development_index  training_hours        target\n",
       "count  18359.000000            18359.000000    18359.000000  18359.000000\n",
       "mean   16729.360096                0.847140       65.899014      0.132088\n",
       "std     9643.749725                0.110189       60.885300      0.338595\n",
       "min        1.000000                0.448000        1.000000      0.000000\n",
       "25%     8378.500000                0.796000       23.000000      0.000000\n",
       "50%    16706.000000                0.910000       47.000000      0.000000\n",
       "75%    25148.500000                0.920000       89.000000      0.000000\n",
       "max    33380.000000                0.949000      336.000000      1.000000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:1: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "train=pd.concat([trained,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import missingno as msno\n",
    "# msno.bar(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "missing values in city are 0.0%\n",
      "missing values in city_development_index are 0.0%\n",
      "missing values in company_size are 26.452965847813058%\n",
      "missing values in company_type are 28.067705212702215%\n",
      "missing values in education_level are 2.5524266027561415%\n",
      "missing values in enrolled_university are 1.860395446375075%\n",
      "missing values in enrollee_id are 0.0%\n",
      "missing values in experience are 0.3085680047932894%\n",
      "missing values in flag are 0.0%\n",
      "missing values in gender are 22.426602756141403%\n",
      "missing values in last_new_job are 2.0101857399640504%\n",
      "missing values in major_discipline are 15.67106051527861%\n",
      "missing values in relevent_experience are 0.0%\n",
      "missing values in target are 45.0%\n",
      "missing values in training_hours are 0.0%\n"
     ]
    }
   ],
   "source": [
    "for i in train.columns:\n",
    "    x=train[i].isna().sum()\n",
    "    print(\"missing values in {} are {}%\".format(i,(x/train.shape[0])*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values in city are 123 \n",
      "unique values in city_development_index are 93 \n",
      "unique values in company_size are 9 \n",
      "unique values in company_type are 7 \n",
      "unique values in education_level are 6 \n",
      "unique values in enrolled_university are 4 \n",
      "unique values in enrollee_id are 33380 \n",
      "unique values in experience are 23 \n",
      "unique values in flag are 2 \n",
      "unique values in gender are 4 \n",
      "unique values in last_new_job are 7 \n",
      "unique values in major_discipline are 7 \n",
      "unique values in relevent_experience are 2 \n",
      "unique values in target are 3 \n",
      "unique values in training_hours are 241 \n"
     ]
    }
   ],
   "source": [
    "#unique_values\n",
    "for i in train.columns:\n",
    "    print(\"unique values in {} are {} \".format(i,len(train[i].unique())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA CLEANING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 33380 entries, 0 to 15020\n",
      "Data columns (total 15 columns):\n",
      "city                      33380 non-null object\n",
      "city_development_index    33380 non-null float64\n",
      "company_size              24550 non-null object\n",
      "company_type              24011 non-null object\n",
      "education_level           32528 non-null object\n",
      "enrolled_university       32759 non-null object\n",
      "enrollee_id               33380 non-null int64\n",
      "experience                33277 non-null object\n",
      "flag                      33380 non-null object\n",
      "gender                    25894 non-null object\n",
      "last_new_job              32709 non-null object\n",
      "major_discipline          28149 non-null object\n",
      "relevent_experience       33380 non-null object\n",
      "target                    18359 non-null float64\n",
      "training_hours            33380 non-null int64\n",
      "dtypes: float64(2), int64(2), object(11)\n",
      "memory usage: 4.1+ MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "city                          0\n",
       "city_development_index        0\n",
       "company_size               8830\n",
       "company_type               9369\n",
       "education_level             852\n",
       "enrolled_university         621\n",
       "enrollee_id                   0\n",
       "experience                  103\n",
       "flag                          0\n",
       "gender                     7486\n",
       "last_new_job                671\n",
       "major_discipline           5231\n",
       "relevent_experience           0\n",
       "target                    15021\n",
       "training_hours                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5190, 15)\n",
      "5231\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------\n",
    "train[\"city\"]=train[\"city\"].str.replace(\"city_\",\"\")\n",
    "train[\"city\"]=pd.to_numeric(train[\"city\"],errors='coerce')\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "train[\"company_type\"]=train[\"company_type\"].fillna(\"Other1\")\n",
    "train[\"company_type\"]=train[\"company_type\"].map({'Pvt Ltd':0, 'Funded Startup':1, 'Public Sector':2, 'Other1':6,\n",
    "                                                 'Early Stage Startup':3, 'NGO':4, 'Other':5})\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "train[\"gender\"]=train[\"gender\"].fillna(\"other\")\n",
    "train[\"gender\"]=train[\"gender\"].map({'Male':1,'other':3,'Female':0,'Other':2})\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "train[\"company_size\"]=train[\"company_size\"].str.replace(\"/\",\"0\")\n",
    "train[\"company_size\"]=train[\"company_size\"].str.replace(\"<\",\"5-\")\n",
    "train[\"company_size\"]=train[\"company_size\"].fillna(\"unknown\")\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "train[\"relevent_experience\"]=train[\"relevent_experience\"].map({'Has relevent experience':1,'No relevent experience':0})\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "# cleaning education level\n",
    "train[\"education_level\"]=train[\"education_level\"].fillna(\"Other_Education_or_not_educated\")\n",
    "train[\"education_level\"]=train[\"education_level\"].map({'Graduate':3, 'Masters':4, 'High School':2, 'Phd':5,\n",
    "       'Other_Education_or_not_educated':0, 'Primary School':1})\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "#filling na  of major with no major because people who have not been graduated are not eligible for majors\n",
    "#people who study less than garduate are not eligible for majors\n",
    "trained_m=train[train[\"education_level\"]<3]\n",
    "print(trained_m.shape)\n",
    "print(train[\"major_discipline\"].isna().sum())\n",
    "train[\"major_discipline\"]=train[\"major_discipline\"].fillna(\"No Major\")\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "#cleaning experience level and filling na\n",
    "train[\"experience\"]=train[\"experience\"].str.replace(\">20\",\"25\")\n",
    "train[\"experience\"]=train[\"experience\"].str.replace(\"<1\",\"0\")\n",
    "train[\"experience\"]=pd.to_numeric(train[\"experience\"],errors='coerce')\n",
    "train[\"experience\"]=train[\"experience\"].fillna(0)\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "train[\"enrolled_university\"]=train[\"enrolled_university\"].fillna(\"no_enrollment\")\n",
    "train[\"enrolled_university\"]=train[\"enrolled_university\"].map({'no_enrollment':0,\n",
    "                                                               'Full time course':1,\n",
    "                                                               'Part time course':2})\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "train[\"last_new_job\"]=train[\"last_new_job\"].str.replace(\"never\",\"0\")\n",
    "\n",
    "train[\"last_new_job\"]=train[\"last_new_job\"].str.replace(\">4\",\"5\")\n",
    "train[\"last_new_job\"]=train[\"last_new_job\"].fillna(\"0\")\n",
    "train[\"last_new_job\"]=pd.to_numeric(train[\"last_new_job\"],errors='coerce')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train[\"company_size\"]=train[\"company_size\"].map({'100-500':2, '5-10':0, '50-99':1, 'unknown':8, '5000-9999':5, '10000+':7,\n",
    "#        '1000-4999':4, '500-999':3, '10049':6})\n",
    "\n",
    "# train[\"major_discipline\"]=train[\"major_discipline\"].map({'STEM':2, 'Other':5, 'No Major':0, 'Business Degree':3, 'Arts':4,\n",
    "#        'Humanities':1})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SOME EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# #checking the target column\n",
    "# plt.figure(figsize=(10,6))\n",
    "# plt.title(\"Target Column values count 1 are {} in number and 0 are {} in number\"\n",
    "#           .format(train[train[\"target\"]==1].shape[0],train[train[\"target\"]==0].shape[0]))\n",
    "# train[\"target\"].plot(kind='hist')\n",
    "# plt.xlabel(\"frequency\")\n",
    "# plt.ylabel(\"target value\")\n",
    "# plt.xticks(ticks=[0,.5,1])\n",
    "\n",
    "\n",
    "# #let see how target 0 columns depends on other columns\n",
    "# target0=train[train[\"target\"]==0]\n",
    "# sns.pairplot(target0)\n",
    "\n",
    "\n",
    "\n",
    "# #let see how target 0 columns depends on other columns\n",
    "# target1=train[train[\"target\"]==1]\n",
    "# sns.pairplot(target1)\n",
    "\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,8))\n",
    "# sns.scatterplot(y=train[\"training_hours\"],x=train[\"experience\"],hue=train[\"target\"])\n",
    "\n",
    "\n",
    "# #plotting the plot for 1 target\n",
    "# data=train[\"experience\"][train[\"target\"]==1].value_counts()\n",
    "# data=pd.DataFrame({\"name\":data.index,\"values\":data.values})\n",
    "# plt.figure(figsize=(10,6))\n",
    "# sns.barplot(data[\"name\"],data[\"values\"])\n",
    "\n",
    "\n",
    "\n",
    "# #plotting the plot for 0 target\n",
    "# data=train[\"experience\"][train[\"target\"]==0].value_counts()\n",
    "# data=pd.DataFrame({\"name\":data.index,\"values\":data.values})\n",
    "# plt.figure(figsize=(10,6))\n",
    "# sns.barplot(data[\"name\"],data[\"values\"])\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,8))\n",
    "# plt.title(\"Experience column counts\")\n",
    "# sns.distplot(train[\"experience\"])\n",
    "# plt.xticks(ticks=np.arange(0,26))\n",
    "\n",
    "\n",
    "\n",
    "# plt.figure(figsize=(10,8))\n",
    "# plt.title(\"Experience vs Training hours vs Target(People who have more training hours are more expecting for job change)\")\n",
    "# sns.barplot(train[\"experience\"],train[\"training_hours\"],hue=train[\"target\"])\n",
    "# #plt.xticks(ticks=np.arange(0,26))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LETS STANDARDIZE THE DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['city', 'city_development_index', 'company_size', 'company_type',\n",
       "       'education_level', 'enrolled_university', 'enrollee_id', 'experience',\n",
       "       'flag', 'gender', 'last_new_job', 'major_discipline',\n",
       "       'relevent_experience', 'target', 'training_hours'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18359, 15)\n",
      "(18359, 38) (15021, 38)\n"
     ]
    }
   ],
   "source": [
    "#---------------------------------------------------------------------------------\n",
    "newdata=pd.get_dummies(data=train,columns=['company_size','major_discipline'],prefix=\"dum\")\n",
    "#---------------------------------------------------------------------------------\n",
    "from sklearn.preprocessing import MinMaxScaler,RobustScaler,StandardScaler\n",
    "mms=MinMaxScaler()\n",
    "ssc=StandardScaler()\n",
    "rs=RobustScaler()\n",
    "# newdata['city'] = ssc.fit_transform(newdata['city'].values.reshape(-1,1))\n",
    "newdata['city'] = ssc.fit_transform(newdata['city'].values.reshape(-1,1))\n",
    "#newdata['experience'] = mms.fit_transform(newdata['experience'].values.reshape(-1,1))\n",
    "newdata[\"engineered_exp_training\"]=round(newdata[\"training_hours\"]/train[\"experience\"],2)\n",
    "newdata[\"engineered_exp_training1\"]=round(newdata[\"training_hours\"]*train[\"experience\"],2)\n",
    "newdata[\"engineered_exp_training\"]=newdata[\"engineered_exp_training\"].fillna(0)\n",
    "#saperating our data\n",
    "print(trained.shape)\n",
    "\n",
    "idx=['city', 'city_development_index', 'experience', 'last_new_job' ,'training_hours']\n",
    "for df in[newdata]:\n",
    "    df['sum'] = round(df[idx].sum(axis=1),2)  \n",
    "    df['min'] = round(df[idx].min(axis=1),2)\n",
    "    df['max'] = round(df[idx].max(axis=1),2)\n",
    "    df['mean'] = round(df[idx].mean(axis=1),2)\n",
    "    df['std'] = round(df[idx].std(axis=1),2)\n",
    "    df['skew'] = round(df[idx].skew(axis=1),2)\n",
    "    df['kurt'] = round(df[idx].kurtosis(axis=1),2)\n",
    "    df['med'] = round(df[idx].median(axis=1),2)\n",
    "\n",
    "trained=newdata[newdata[\"flag\"]=='train']\n",
    "test=newdata[newdata[\"flag\"]=='test']\n",
    "print(trained.shape,test.shape)\n",
    "\n",
    "    \n",
    "# #saperating our data\n",
    "# print(trained.shape)\n",
    "# trained=newdata[newdata[\"flag\"]=='train']\n",
    "# test=newdata[newdata[\"flag\"]=='test']\n",
    "# print(trained.shape,test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODELLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18359, 35) (18359,)\n"
     ]
    }
   ],
   "source": [
    "#splitting the data into test train \n",
    "training,validation=train_test_split(trained,test_size=.30,random_state=42)\n",
    "training.shape,validation.shape\n",
    "\n",
    "\n",
    "# full_train=train[train[\"flag\"]==\"train\"]\n",
    "# full_train_x=full_train.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "# full_train_y=full_train[\"target\"]\n",
    "\n",
    "full_train=newdata[newdata[\"flag\"]==\"train\"]\n",
    "full_train_x=full_train.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "full_train_y=full_train[\"target\"]\n",
    "print(full_train_x.shape,full_train_y.shape)\n",
    "# #---------------------smote\n",
    "# sm = SMOTE(random_state = 2) \n",
    "# x_train_smote_full, y_train_smote_full = sm.fit_sample(full_train_x, full_train_y.ravel()) \n",
    "\n",
    "\n",
    "\n",
    "#######################################################Artificially oversampling using smote \n",
    "#saperating x and y\n",
    "# training_x=x_train_smote_full.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "# training_y=training[\"target\"]\n",
    "# validation_x=validation.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "# validation_y=validation[\"target\"]\n",
    "\n",
    "#--------------------------------------------------------------------\n",
    "test_final=test.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "\n",
    "#saperating x and y\n",
    "training_x=training.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "training_y=training[\"target\"]\n",
    "validation_x=validation.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "validation_y=validation[\"target\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15021, 35)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc=LogisticRegression(class_weight='balanced')\n",
    "# gbc=GradientBoostingClassifier()\n",
    "# rfc=RandomForestClassifier(class_weight='balanced')\n",
    "# etc=ExtraTreeClassifier(class_weight='balanced')\n",
    "# dtc=DecisionTreeClassifier(class_weight='balanced')\n",
    "# abc=AdaBoostClassifier()\n",
    "# svc=SVC(class_weight='balanced')\n",
    "pac=PassiveAggressiveClassifier(class_weight='balanced')\n",
    "rc=RidgeClassifierCV(class_weight='balanced')\n",
    "sgc=SGDClassifier(class_weight='balanced')\n",
    "enc=ElasticNetCV()\n",
    "gnbc=GaussianNB()\n",
    "knc=KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.6139898024637205, tolerance: 0.11653307392996097\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.35929573279418037, tolerance: 0.11609082774049216\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:472: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.66299688974118, tolerance: 0.11609082774049216\n",
      "  tol, rng, random, positive)\n",
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:476: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.257069589705452, tolerance: 0.14433474437786908\n",
      "  positive)\n",
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "                     metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "                     weights='uniform')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pac.fit(training_x,training_y)\n",
    "rc.fit(training_x,training_y)\n",
    "sgc.fit(training_x,training_y)\n",
    "enc.fit(training_x,training_y)\n",
    "lrc.fit(training_x,training_y)\n",
    "gnbc.fit(training_x,training_y)\n",
    "knc.fit(training_x,training_y)\n",
    "\n",
    "# gbc.fit(training_x,training_y)\n",
    "# rfc.fit(training_x,training_y)\n",
    "# etc.fit(training_x,training_y)\n",
    "# dtc.fit(training_x,training_y)\n",
    "# abc.fit(training_x,training_y)\n",
    "# svc.fit(training_x,training_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prediction\n",
    "pr_lrc=lrc.predict(validation_x)\n",
    "pr_rc=rc.predict(validation_x)\n",
    "\n",
    "pr_sgc=sgc.predict(validation_x)\n",
    "pr_enc=enc.predict(validation_x)\n",
    "pr_pac=pac.predict(validation_x)\n",
    "pr_gnbc=gnbc.predict(validation_x)\n",
    "pr_knn=knc.predict(validation_x)\n",
    "\n",
    "# pr_gbc=gbc.predict(validation_x)\n",
    "# pr_rfc=rfc.predict(validation_x)\n",
    "# pr_etc=etc.predict(validation_x)\n",
    "# pr_dtc=dtc.predict(validation_x)\n",
    "# pr_abc=abc.predict(validation_x)\n",
    "\n",
    "#predicted prob\n",
    "proba_lrc=lrc.predict(validation_x)\n",
    "# proba_gbc=gbc.predict(validation_x)\n",
    "# proba_rfc=rfc.predict(validation_x)\n",
    "# proba_etc=etc.predict(validation_x)\n",
    "# proba_dtc=dtc.predict(validation_x)\n",
    "# proba_abc=abc.predict(validation_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.543000573163167\n",
      "0.5585282985993476\n",
      "0.5492113291605654\n",
      "0.5577159163706249\n",
      "0.5549130245027745\n",
      "0.5300541031413077\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,auc,roc_auc_score\n",
    "# print(classification_report(pr_lrc,validation_y))\n",
    "# print(classification_report(pr_gbc,validation_y))\n",
    "# print(classification_report(pr_rfc,validation_y))\n",
    "# print(classification_report(pr_etc,validation_y))\n",
    "# print(classification_report(pr_dtc,validation_y))\n",
    "# print(classification_report(pr_abc,validation_y))\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_auc_score\n",
    "print(roc_auc_score(pr_lrc,validation_y))\n",
    "print(roc_auc_score(pr_rc,validation_y))\n",
    "print(roc_auc_score(pr_sgc,validation_y))\n",
    "print(roc_auc_score(pr_pac,validation_y))\n",
    "#print(roc_auc_score(pr_enc,validation_y))\n",
    "print(roc_auc_score(pr_gnbc,validation_y))\n",
    "print(roc_auc_score(pr_knn,validation_y))\n",
    "\n",
    "# print(roc_auc_score(pr_gbc,validation_y))\n",
    "# print(roc_auc_score(pr_rfc,validation_y))\n",
    "# print(roc_auc_score(pr_etc,validation_y))\n",
    "# print(roc_auc_score(pr_dtc,validation_y))\n",
    "# print(roc_auc_score(pr_abc,validation_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.446127\n",
       "1       -0.008823\n",
       "2       -1.485818\n",
       "3       -0.427672\n",
       "4        0.365937\n",
       "           ...   \n",
       "18354    0.432071\n",
       "18355    1.688618\n",
       "18356    0.674562\n",
       "18357   -0.185181\n",
       "18358    0.476160\n",
       "Name: city, Length: 18359, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_train_x[\"city\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tn1, fp1, fn1, tp1 = confusion_matrix(pr_lrc,validation_y).ravel()\n",
    "# # =confusion_matrix(pr_lrc,validation_y).ravel()\n",
    "# tn2, fp2, fn2, tp2=confusion_matrix(pr_gbc,validation_y).ravel()\n",
    "# tn3, fp3, fn3, tp3=confusion_matrix(pr_rfc,validation_y).ravel()\n",
    "# tn4, fp4, fn4, tp4=confusion_matrix(pr_etc,validation_y).ravel()\n",
    "# tn5, fp5, fn5, tp5=confusion_matrix(pr_dtc,validation_y).ravel()\n",
    "# tn6, fp6, fn6, tp6=confusion_matrix(pr_abc,validation_y).ravel()\n",
    "\n",
    "# print(tn1, fp1, fn1, tp1)\n",
    "# print(tn2, fp2, fn2, tp2)\n",
    "# print(tn3, fp3, fn3, tp3)\n",
    "# print(tn4, fp4, fn4, tp4)\n",
    "# print(tn5, fp5, fn5, tp5)\n",
    "# print(tn6, fp6, fn6, tp6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (y_train_smote_full==0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to get variable importances\n",
    "def plot_graph(a):\n",
    "    plt.figure(figsize=(20,12))\n",
    "    chart=sns.barplot(x=a[\"name_of_column\"],y=a[\"feature_importance\"])\n",
    "    chart.set_xticklabels(chart.get_xticklabels(), rotation=90)\n",
    "def feature_importance_plot_rev(dataframe,classifier,limit_of_the_importance):\n",
    "    x=list(zip(dataframe.columns,classifier.feature_importances_))\n",
    "    xx=pd.DataFrame(x)\n",
    "    xx.columns=[\"name_of_column\",\"feature_importance\"]\n",
    "    xx=xx.sort_values(\"feature_importance\",ascending=False)\n",
    "    xx=xx[xx[\"feature_importance\"]>limit_of_the_importance]\n",
    "    plot_graph(xx)\n",
    "    return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "# feature_importance_plot_rev(training_x,rfc,0)\n",
    "\n",
    "# feature_importance_plot_rev(training_x,dtc,0)\n",
    "\n",
    "# feature_importance_plot_rev(training_x,etc,0)\n",
    "\n",
    "# feature_importance_plot_rev(training_x,gbc,0)\n",
    "\n",
    "\n",
    "#abc is giving good results\n",
    "#feature_importance_plot_rev(training_x,abc,0)\n",
    "\n",
    "# abc.fit(full_train_x,full_train_y)\n",
    "# test_final=test.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "# predicted_final_abc=abc.predict(test_final)\n",
    "\n",
    "# #-------------------rfc predicted\n",
    "# rfc.fit(x_train_smote_full,y_train_smote_full)\n",
    "# test_final=test.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "# predicted_final_rfc=rfc.predict(test_final)\n",
    "# prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_rfc})\n",
    "# prediction.to_csv('predicted1_rfc_bal_ssc_smote.csv',index=False)\n",
    "\n",
    "\n",
    "# #-----------------etc predicted\n",
    "# etc.fit(x_train_smote_full,y_train_smote_full)\n",
    "# test_final=test.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "# predicted_final_etc=etc.predict(test_final)\n",
    "# prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_etc})\n",
    "# prediction.to_csv('predicted1_etc_bal_ssc_smote.csv',index=False)\n",
    "\n",
    "\n",
    "# # # #\n",
    "# #----------------dtc precicted\n",
    "# dtc.fit(x_train_smote_full,y_train_smote_full)\n",
    "# test_final=test.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "# predicted_final_dtc=dtc.predict(test_final)\n",
    "# prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_dtc})\n",
    "# prediction.to_csv('predicted1_dtc_bal_ssc_smote.csv',index=False)\n",
    "\n",
    "# #------------------svc\n",
    "\n",
    "# svc.fit(x_train_smote_full,y_train_smote_full)\n",
    "# test_final=test.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "# predicted_final_svc=svc.predict(test_final)\n",
    "# prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_svc})\n",
    "# prediction.to_csv('predicted1_svc_ssc.smote.csv',index=False)\n",
    "\n",
    "\n",
    "#----------------------------------lgc\n",
    "# selected_data=full_train_x[['training_hours', 'experience', 'city_development_index', 'city', 'last_new_job',\n",
    "#                            'education_level', 'company_type', 'gender', 'enrolled_university', 'relevent_experience',\n",
    "#                            'dum_unknown', 'dum_50-99', 'dum_STEM','dum_100-500', 'dum_10000+', 'dum_1000-4999']]\n",
    "# selected_data_test=test[['training_hours', 'experience', 'city_development_index', 'city', 'last_new_job',\n",
    "#                            'education_level', 'company_type', 'gender', 'enrolled_university', 'relevent_experience',\n",
    "#                            'dum_unknown', 'dum_50-99', 'dum_STEM','dum_100-500', 'dum_10000+', 'dum_1000-4999']]\n",
    "\n",
    "#--------------passive REGRESSION\n",
    "#not working\n",
    "pac.fit(full_train_x,full_train_y)\n",
    "predicted_final_pac=pac.predict(test_final)\n",
    "#print(classification_report(predicted_final_lrc,validation_y))\n",
    "prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_pac})\n",
    "prediction.to_csv('predicted1_pac_bal_standardscaler.csv',index=False)\n",
    "#--------------SGC\n",
    "sgc.fit(full_train_x,full_train_y)\n",
    "predicted_final_sgc=sgc.predict(test_final)\n",
    "#print(classification_report(predicted_final_lrc,validation_y))\n",
    "prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_sgc})\n",
    "prediction.to_csv('predicted1_sgc_bal_standardscaler.csv',index=False)\n",
    "\n",
    "\n",
    "#--------------LOGISTIC REGRESSION\n",
    "lrc.fit(full_train_x,full_train_y)\n",
    "predicted_final_lrc=lrc.predict(test_final)\n",
    "#print(classification_report(predicted_final_lrc,validation_y))\n",
    "prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_lrc})\n",
    "prediction.to_csv('predicted1_lrc_bal_standardscaler.csv',index=False)\n",
    "#--------------elastic REGRESSION\n",
    "#done-working\n",
    "enc.fit(full_train_x,full_train_y)\n",
    "predicted_final_enc=enc.predict(test_final)\n",
    "#print(classification_report(predicted_final_lrc,validation_y))\n",
    "prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_enc})\n",
    "prediction.to_csv('predicted1_enc_bal_standardscaler.csv',index=False)\n",
    "\n",
    "#--------------ridge\n",
    "#done working\n",
    "rc.fit(full_train_x,full_train_y)\n",
    "predicted_final_rc=rc.predict(test_final)\n",
    "#print(classification_report(predicted_final_lrc,validation_y))\n",
    "prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_rc})\n",
    "prediction.to_csv('predicted1_rc_bal_standardscaler.csv',index=False)\n",
    "\n",
    "#--------------NB\n",
    "#done not working\n",
    "gnbc.fit(full_train_x,full_train_y)\n",
    "predicted_final_gnbc=gnbc.predict(test_final)\n",
    "#print(classification_report(predicted_final_lrc,validation_y))\n",
    "prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_gnbc})\n",
    "prediction.to_csv('predicted1_gnbc_bal_standardscaler.csv',index=False)\n",
    "\n",
    "\n",
    "#---------------knn\n",
    "#done not working\n",
    "knc.fit(full_train_x,full_train_y)\n",
    "predicted_final_knc=knc.predict(test_final)\n",
    "#print(classification_report(predicted_final_lrc,validation_y))\n",
    "prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_knc})\n",
    "prediction.to_csv('predicted1_knc_bal_standardscaler.csv',index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_features_to_be_considered_frc=feature_importance_plot_rev(training_x,rfc,.01)\n",
    "# columns_considered=final_features_to_be_considered_frc[\"name_of_column\"]\n",
    "# print(columns_considered.values)\n",
    "\n",
    "\n",
    "#stacking several models\n",
    "\n",
    "# lrc=LogisticRegression(class_weight='balanced')\n",
    "# pac=PassiveAggressiveClassifier(class_weight='balanced')\n",
    "# rc=RidgeClassifierCV(class_weight='balanced')\n",
    "# #sgc=SGDClassifier(class_weight='balanced')\n",
    "# enc=ElasticNetCV()\n",
    "# gnbc=GaussianNB()\n",
    "# knc=KNeighborsClassifier()\n",
    "\n",
    "level0=list()\n",
    "level0.append(('lr',LogisticRegression()))\n",
    "level0.append(('pac',PassiveAggressiveClassifier()))\n",
    "level0.append(('rc',RidgeClassifierCV()))\n",
    "level0.append(('gnbc',GaussianNB()))\n",
    "\n",
    "level1 = LogisticRegression()\n",
    "# define the stacking ensemble\n",
    "model = StackingClassifier(estimators=level0, final_estimator=level1, cv=5)\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor\n",
    "# rfr=AdaBoostRegressor()\n",
    "# rfr.fit(full_train_x,full_train_y)\n",
    "# test_final=test.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "# predicted_final_rfr=rfr.predict(test_final)\n",
    "# #print(classification_report(predicted_final_lrc,validation_y))\n",
    "# prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_rfr})\n",
    "# prediction.to_csv('predicted1_stacking_adar_bal_standardscaler.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "model.fit(full_train_x,full_train_y)\n",
    "test_final=test.drop([\"target\",\"flag\",\"enrollee_id\"],axis=1)\n",
    "predicted_final_stacking=model.predict(test_final)\n",
    "#print(classification_report(predicted_final_lrc,validation_y))\n",
    "prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_stacking})\n",
    "prediction.to_csv('predicted1_stacking2_bal_standardscaler.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>city_development_index</th>\n",
       "      <th>company_type</th>\n",
       "      <th>education_level</th>\n",
       "      <th>enrolled_university</th>\n",
       "      <th>enrollee_id</th>\n",
       "      <th>experience</th>\n",
       "      <th>gender</th>\n",
       "      <th>last_new_job</th>\n",
       "      <th>relevent_experience</th>\n",
       "      <th>...</th>\n",
       "      <th>engineered_exp_training</th>\n",
       "      <th>engineered_exp_training1</th>\n",
       "      <th>sum</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>skew</th>\n",
       "      <th>kurt</th>\n",
       "      <th>med</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>city</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.326516</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>-0.002657</td>\n",
       "      <td>-0.005467</td>\n",
       "      <td>-0.011282</td>\n",
       "      <td>0.096489</td>\n",
       "      <td>-0.028777</td>\n",
       "      <td>0.058492</td>\n",
       "      <td>-0.018078</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.046996</td>\n",
       "      <td>0.050736</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>0.948033</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.029513</td>\n",
       "      <td>-0.006551</td>\n",
       "      <td>0.017273</td>\n",
       "      <td>-0.020697</td>\n",
       "      <td>0.112493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>city_development_index</td>\n",
       "      <td>0.326516</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.076021</td>\n",
       "      <td>0.037206</td>\n",
       "      <td>-0.123983</td>\n",
       "      <td>-0.033675</td>\n",
       "      <td>0.294039</td>\n",
       "      <td>-0.135284</td>\n",
       "      <td>0.175051</td>\n",
       "      <td>0.062381</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.124718</td>\n",
       "      <td>0.152020</td>\n",
       "      <td>0.039980</td>\n",
       "      <td>0.397434</td>\n",
       "      <td>-0.005744</td>\n",
       "      <td>0.039961</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>-0.102248</td>\n",
       "      <td>-0.127670</td>\n",
       "      <td>0.181854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>company_type</td>\n",
       "      <td>0.008261</td>\n",
       "      <td>-0.076021</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.194197</td>\n",
       "      <td>0.124255</td>\n",
       "      <td>0.036118</td>\n",
       "      <td>-0.141304</td>\n",
       "      <td>0.070387</td>\n",
       "      <td>-0.205868</td>\n",
       "      <td>-0.343095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101347</td>\n",
       "      <td>-0.060844</td>\n",
       "      <td>-0.007727</td>\n",
       "      <td>-0.040787</td>\n",
       "      <td>0.015105</td>\n",
       "      <td>-0.007726</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>0.098780</td>\n",
       "      <td>0.097089</td>\n",
       "      <td>-0.173393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>education_level</td>\n",
       "      <td>-0.002657</td>\n",
       "      <td>0.037206</td>\n",
       "      <td>-0.194197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.092788</td>\n",
       "      <td>-0.017951</td>\n",
       "      <td>0.251671</td>\n",
       "      <td>-0.075039</td>\n",
       "      <td>0.203493</td>\n",
       "      <td>0.234385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.156325</td>\n",
       "      <td>0.138409</td>\n",
       "      <td>0.028095</td>\n",
       "      <td>0.046209</td>\n",
       "      <td>-0.006523</td>\n",
       "      <td>0.028094</td>\n",
       "      <td>-0.008948</td>\n",
       "      <td>-0.127144</td>\n",
       "      <td>-0.134116</td>\n",
       "      <td>0.165843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>enrolled_university</td>\n",
       "      <td>-0.005467</td>\n",
       "      <td>-0.123983</td>\n",
       "      <td>0.124255</td>\n",
       "      <td>-0.092788</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018923</td>\n",
       "      <td>-0.264712</td>\n",
       "      <td>0.069155</td>\n",
       "      <td>-0.165547</td>\n",
       "      <td>-0.243483</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139156</td>\n",
       "      <td>-0.133904</td>\n",
       "      <td>-0.014384</td>\n",
       "      <td>-0.025925</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>-0.014377</td>\n",
       "      <td>0.023335</td>\n",
       "      <td>0.125051</td>\n",
       "      <td>0.134626</td>\n",
       "      <td>-0.159833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>enrollee_id</td>\n",
       "      <td>-0.011282</td>\n",
       "      <td>-0.033675</td>\n",
       "      <td>0.036118</td>\n",
       "      <td>-0.017951</td>\n",
       "      <td>0.018923</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.028400</td>\n",
       "      <td>-0.037870</td>\n",
       "      <td>-0.024685</td>\n",
       "      <td>-0.026482</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>-0.010444</td>\n",
       "      <td>-0.003393</td>\n",
       "      <td>-0.006930</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>-0.003395</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>0.025768</td>\n",
       "      <td>-0.036435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>experience</td>\n",
       "      <td>0.096489</td>\n",
       "      <td>0.294039</td>\n",
       "      <td>-0.141304</td>\n",
       "      <td>0.251671</td>\n",
       "      <td>-0.264712</td>\n",
       "      <td>-0.028400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.123199</td>\n",
       "      <td>0.466230</td>\n",
       "      <td>0.316400</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.376779</td>\n",
       "      <td>0.529505</td>\n",
       "      <td>0.140990</td>\n",
       "      <td>0.156551</td>\n",
       "      <td>0.013826</td>\n",
       "      <td>0.140985</td>\n",
       "      <td>0.008935</td>\n",
       "      <td>-0.430413</td>\n",
       "      <td>-0.475302</td>\n",
       "      <td>0.471674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>gender</td>\n",
       "      <td>-0.028777</td>\n",
       "      <td>-0.135284</td>\n",
       "      <td>0.070387</td>\n",
       "      <td>-0.075039</td>\n",
       "      <td>0.069155</td>\n",
       "      <td>-0.037870</td>\n",
       "      <td>-0.123199</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.102991</td>\n",
       "      <td>-0.113295</td>\n",
       "      <td>...</td>\n",
       "      <td>0.063815</td>\n",
       "      <td>-0.065514</td>\n",
       "      <td>-0.015944</td>\n",
       "      <td>-0.066261</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>-0.015942</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>0.050692</td>\n",
       "      <td>0.055928</td>\n",
       "      <td>-0.084272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>last_new_job</td>\n",
       "      <td>0.058492</td>\n",
       "      <td>0.175051</td>\n",
       "      <td>-0.205868</td>\n",
       "      <td>0.203493</td>\n",
       "      <td>-0.165547</td>\n",
       "      <td>-0.024685</td>\n",
       "      <td>0.466230</td>\n",
       "      <td>-0.102991</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.236494</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.214083</td>\n",
       "      <td>0.242299</td>\n",
       "      <td>0.082661</td>\n",
       "      <td>0.134875</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.082657</td>\n",
       "      <td>-0.007864</td>\n",
       "      <td>-0.250592</td>\n",
       "      <td>-0.225901</td>\n",
       "      <td>0.970705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>relevent_experience</td>\n",
       "      <td>-0.018078</td>\n",
       "      <td>0.062381</td>\n",
       "      <td>-0.343095</td>\n",
       "      <td>0.234385</td>\n",
       "      <td>-0.243483</td>\n",
       "      <td>-0.026482</td>\n",
       "      <td>0.316400</td>\n",
       "      <td>-0.113295</td>\n",
       "      <td>0.236494</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.194672</td>\n",
       "      <td>0.174792</td>\n",
       "      <td>0.052301</td>\n",
       "      <td>0.037885</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>0.052299</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>-0.157420</td>\n",
       "      <td>-0.166785</td>\n",
       "      <td>0.195557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>target</td>\n",
       "      <td>-0.042851</td>\n",
       "      <td>-0.127290</td>\n",
       "      <td>0.090565</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.063714</td>\n",
       "      <td>0.034132</td>\n",
       "      <td>-0.075269</td>\n",
       "      <td>0.029406</td>\n",
       "      <td>-0.032323</td>\n",
       "      <td>-0.072328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032656</td>\n",
       "      <td>-0.045601</td>\n",
       "      <td>-0.016383</td>\n",
       "      <td>-0.051095</td>\n",
       "      <td>-0.005414</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>-0.004552</td>\n",
       "      <td>0.032380</td>\n",
       "      <td>0.037553</td>\n",
       "      <td>-0.037498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>training_hours</td>\n",
       "      <td>-0.001281</td>\n",
       "      <td>-0.009960</td>\n",
       "      <td>0.016356</td>\n",
       "      <td>-0.010150</td>\n",
       "      <td>0.024941</td>\n",
       "      <td>0.001209</td>\n",
       "      <td>-0.003184</td>\n",
       "      <td>0.003546</td>\n",
       "      <td>-0.006351</td>\n",
       "      <td>0.005144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.528059</td>\n",
       "      <td>0.692075</td>\n",
       "      <td>0.989112</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.998778</td>\n",
       "      <td>0.989113</td>\n",
       "      <td>0.998511</td>\n",
       "      <td>0.501058</td>\n",
       "      <td>0.485772</td>\n",
       "      <td>-0.000597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_100-500</td>\n",
       "      <td>0.020188</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>-0.179839</td>\n",
       "      <td>0.065624</td>\n",
       "      <td>-0.059769</td>\n",
       "      <td>-0.021824</td>\n",
       "      <td>0.047184</td>\n",
       "      <td>-0.031314</td>\n",
       "      <td>0.062041</td>\n",
       "      <td>0.120378</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037741</td>\n",
       "      <td>0.004943</td>\n",
       "      <td>-0.006813</td>\n",
       "      <td>0.035074</td>\n",
       "      <td>-0.014213</td>\n",
       "      <td>-0.006814</td>\n",
       "      <td>-0.014315</td>\n",
       "      <td>-0.056224</td>\n",
       "      <td>-0.057749</td>\n",
       "      <td>0.050385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_1000-4999</td>\n",
       "      <td>0.007163</td>\n",
       "      <td>0.058456</td>\n",
       "      <td>-0.135759</td>\n",
       "      <td>0.072420</td>\n",
       "      <td>-0.028987</td>\n",
       "      <td>0.001242</td>\n",
       "      <td>0.071840</td>\n",
       "      <td>-0.015671</td>\n",
       "      <td>0.072702</td>\n",
       "      <td>0.049710</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.045642</td>\n",
       "      <td>0.032012</td>\n",
       "      <td>-0.004468</td>\n",
       "      <td>0.024437</td>\n",
       "      <td>-0.016124</td>\n",
       "      <td>-0.004469</td>\n",
       "      <td>-0.016917</td>\n",
       "      <td>-0.042636</td>\n",
       "      <td>-0.046992</td>\n",
       "      <td>0.066451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_10000+</td>\n",
       "      <td>-0.005784</td>\n",
       "      <td>0.060714</td>\n",
       "      <td>-0.210462</td>\n",
       "      <td>0.094248</td>\n",
       "      <td>-0.012975</td>\n",
       "      <td>0.020314</td>\n",
       "      <td>0.064204</td>\n",
       "      <td>-0.011603</td>\n",
       "      <td>0.092561</td>\n",
       "      <td>0.059702</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.042426</td>\n",
       "      <td>0.021281</td>\n",
       "      <td>-0.005091</td>\n",
       "      <td>0.019055</td>\n",
       "      <td>-0.014861</td>\n",
       "      <td>-0.005092</td>\n",
       "      <td>-0.015590</td>\n",
       "      <td>-0.051835</td>\n",
       "      <td>-0.050030</td>\n",
       "      <td>0.083445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_10049</td>\n",
       "      <td>-0.006502</td>\n",
       "      <td>-0.028112</td>\n",
       "      <td>-0.106835</td>\n",
       "      <td>0.012754</td>\n",
       "      <td>0.027423</td>\n",
       "      <td>0.006787</td>\n",
       "      <td>-0.028797</td>\n",
       "      <td>-0.017519</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.073906</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015821</td>\n",
       "      <td>-0.006155</td>\n",
       "      <td>0.011209</td>\n",
       "      <td>-0.005779</td>\n",
       "      <td>0.014288</td>\n",
       "      <td>0.011209</td>\n",
       "      <td>0.014274</td>\n",
       "      <td>0.021528</td>\n",
       "      <td>0.023320</td>\n",
       "      <td>-0.008023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_5-10</td>\n",
       "      <td>-0.008243</td>\n",
       "      <td>-0.016571</td>\n",
       "      <td>-0.091602</td>\n",
       "      <td>-0.000785</td>\n",
       "      <td>0.010082</td>\n",
       "      <td>-0.008009</td>\n",
       "      <td>-0.016161</td>\n",
       "      <td>0.001779</td>\n",
       "      <td>-0.013699</td>\n",
       "      <td>0.051203</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015851</td>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.008091</td>\n",
       "      <td>-0.009157</td>\n",
       "      <td>0.010113</td>\n",
       "      <td>0.008091</td>\n",
       "      <td>0.010168</td>\n",
       "      <td>0.011403</td>\n",
       "      <td>0.012250</td>\n",
       "      <td>-0.019344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_50-99</td>\n",
       "      <td>-0.001613</td>\n",
       "      <td>0.017317</td>\n",
       "      <td>-0.212112</td>\n",
       "      <td>0.057166</td>\n",
       "      <td>-0.048241</td>\n",
       "      <td>-0.010218</td>\n",
       "      <td>0.003641</td>\n",
       "      <td>-0.016128</td>\n",
       "      <td>0.024404</td>\n",
       "      <td>0.143629</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020835</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>0.014615</td>\n",
       "      <td>0.013668</td>\n",
       "      <td>0.013622</td>\n",
       "      <td>0.014617</td>\n",
       "      <td>0.012795</td>\n",
       "      <td>0.012249</td>\n",
       "      <td>0.012595</td>\n",
       "      <td>0.008080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_500-999</td>\n",
       "      <td>-0.008541</td>\n",
       "      <td>0.005889</td>\n",
       "      <td>-0.103127</td>\n",
       "      <td>0.040895</td>\n",
       "      <td>-0.030522</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>0.026732</td>\n",
       "      <td>-0.010730</td>\n",
       "      <td>0.026620</td>\n",
       "      <td>0.056579</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020299</td>\n",
       "      <td>0.009055</td>\n",
       "      <td>-0.003378</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>-0.007621</td>\n",
       "      <td>-0.003378</td>\n",
       "      <td>-0.007846</td>\n",
       "      <td>-0.023448</td>\n",
       "      <td>-0.021442</td>\n",
       "      <td>0.020533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_5000-9999</td>\n",
       "      <td>0.009563</td>\n",
       "      <td>0.031192</td>\n",
       "      <td>-0.070107</td>\n",
       "      <td>0.033963</td>\n",
       "      <td>-0.018704</td>\n",
       "      <td>-0.002995</td>\n",
       "      <td>0.030954</td>\n",
       "      <td>-0.008924</td>\n",
       "      <td>0.054125</td>\n",
       "      <td>0.019917</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.013689</td>\n",
       "      <td>0.007908</td>\n",
       "      <td>0.004056</td>\n",
       "      <td>0.018314</td>\n",
       "      <td>-0.000131</td>\n",
       "      <td>0.004053</td>\n",
       "      <td>-0.000679</td>\n",
       "      <td>-0.013262</td>\n",
       "      <td>-0.011002</td>\n",
       "      <td>0.050101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_unknown</td>\n",
       "      <td>-0.005905</td>\n",
       "      <td>-0.089558</td>\n",
       "      <td>0.757133</td>\n",
       "      <td>-0.253906</td>\n",
       "      <td>0.116157</td>\n",
       "      <td>0.012442</td>\n",
       "      <td>-0.128786</td>\n",
       "      <td>0.075263</td>\n",
       "      <td>-0.208687</td>\n",
       "      <td>-0.403901</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102540</td>\n",
       "      <td>-0.056109</td>\n",
       "      <td>-0.012288</td>\n",
       "      <td>-0.066960</td>\n",
       "      <td>0.009224</td>\n",
       "      <td>-0.012287</td>\n",
       "      <td>0.011319</td>\n",
       "      <td>0.094574</td>\n",
       "      <td>0.093348</td>\n",
       "      <td>-0.161101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_Arts</td>\n",
       "      <td>0.019528</td>\n",
       "      <td>0.055948</td>\n",
       "      <td>-0.001131</td>\n",
       "      <td>0.015839</td>\n",
       "      <td>-0.027260</td>\n",
       "      <td>0.008120</td>\n",
       "      <td>0.000791</td>\n",
       "      <td>-0.003449</td>\n",
       "      <td>0.013491</td>\n",
       "      <td>0.009974</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006372</td>\n",
       "      <td>-0.009834</td>\n",
       "      <td>-0.007077</td>\n",
       "      <td>0.026923</td>\n",
       "      <td>-0.008129</td>\n",
       "      <td>-0.007077</td>\n",
       "      <td>-0.008243</td>\n",
       "      <td>-0.003835</td>\n",
       "      <td>0.002102</td>\n",
       "      <td>0.011122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_Business Degree</td>\n",
       "      <td>0.008899</td>\n",
       "      <td>0.029505</td>\n",
       "      <td>-0.030721</td>\n",
       "      <td>0.036759</td>\n",
       "      <td>-0.013590</td>\n",
       "      <td>0.006316</td>\n",
       "      <td>0.009262</td>\n",
       "      <td>-0.002940</td>\n",
       "      <td>0.021175</td>\n",
       "      <td>-0.014636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008337</td>\n",
       "      <td>-0.001049</td>\n",
       "      <td>-0.004334</td>\n",
       "      <td>0.017874</td>\n",
       "      <td>-0.005764</td>\n",
       "      <td>-0.004333</td>\n",
       "      <td>-0.005799</td>\n",
       "      <td>0.001869</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>0.014634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_Humanities</td>\n",
       "      <td>0.029599</td>\n",
       "      <td>0.081274</td>\n",
       "      <td>-0.001001</td>\n",
       "      <td>0.083053</td>\n",
       "      <td>-0.058258</td>\n",
       "      <td>0.021302</td>\n",
       "      <td>0.012673</td>\n",
       "      <td>-0.046066</td>\n",
       "      <td>0.028666</td>\n",
       "      <td>-0.010090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006514</td>\n",
       "      <td>0.005967</td>\n",
       "      <td>0.006053</td>\n",
       "      <td>0.044852</td>\n",
       "      <td>0.004016</td>\n",
       "      <td>0.006050</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.001298</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.019189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_No Major</td>\n",
       "      <td>0.008188</td>\n",
       "      <td>0.009186</td>\n",
       "      <td>0.237697</td>\n",
       "      <td>-0.716364</td>\n",
       "      <td>0.098810</td>\n",
       "      <td>-0.003251</td>\n",
       "      <td>-0.211713</td>\n",
       "      <td>0.078444</td>\n",
       "      <td>-0.206862</td>\n",
       "      <td>-0.316676</td>\n",
       "      <td>...</td>\n",
       "      <td>0.146475</td>\n",
       "      <td>-0.115855</td>\n",
       "      <td>-0.027995</td>\n",
       "      <td>-0.042015</td>\n",
       "      <td>0.002216</td>\n",
       "      <td>-0.027995</td>\n",
       "      <td>0.004512</td>\n",
       "      <td>0.114483</td>\n",
       "      <td>0.116012</td>\n",
       "      <td>-0.162239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_Other</td>\n",
       "      <td>-0.002361</td>\n",
       "      <td>0.008300</td>\n",
       "      <td>0.009279</td>\n",
       "      <td>0.043551</td>\n",
       "      <td>-0.021818</td>\n",
       "      <td>0.020341</td>\n",
       "      <td>0.003937</td>\n",
       "      <td>-0.002296</td>\n",
       "      <td>0.014891</td>\n",
       "      <td>-0.002179</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.003965</td>\n",
       "      <td>0.005558</td>\n",
       "      <td>0.000470</td>\n",
       "      <td>0.006932</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>-0.000696</td>\n",
       "      <td>-0.004635</td>\n",
       "      <td>-0.001311</td>\n",
       "      <td>0.009726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>dum_STEM</td>\n",
       "      <td>-0.027176</td>\n",
       "      <td>-0.070080</td>\n",
       "      <td>-0.195405</td>\n",
       "      <td>0.544909</td>\n",
       "      <td>-0.040338</td>\n",
       "      <td>-0.017049</td>\n",
       "      <td>0.170584</td>\n",
       "      <td>-0.044065</td>\n",
       "      <td>0.148980</td>\n",
       "      <td>0.276712</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.130666</td>\n",
       "      <td>0.097314</td>\n",
       "      <td>0.024258</td>\n",
       "      <td>0.001289</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.024259</td>\n",
       "      <td>-0.001451</td>\n",
       "      <td>-0.096207</td>\n",
       "      <td>-0.099649</td>\n",
       "      <td>0.119354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>engineered_exp_training</td>\n",
       "      <td>-0.046996</td>\n",
       "      <td>-0.124718</td>\n",
       "      <td>0.101347</td>\n",
       "      <td>-0.156325</td>\n",
       "      <td>0.139156</td>\n",
       "      <td>0.018136</td>\n",
       "      <td>-0.376779</td>\n",
       "      <td>0.063815</td>\n",
       "      <td>-0.214083</td>\n",
       "      <td>-0.194672</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.007487</td>\n",
       "      <td>0.467080</td>\n",
       "      <td>-0.069601</td>\n",
       "      <td>0.526768</td>\n",
       "      <td>0.467078</td>\n",
       "      <td>0.534223</td>\n",
       "      <td>0.368651</td>\n",
       "      <td>0.362122</td>\n",
       "      <td>-0.197252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>engineered_exp_training1</td>\n",
       "      <td>0.050736</td>\n",
       "      <td>0.152020</td>\n",
       "      <td>-0.060844</td>\n",
       "      <td>0.138409</td>\n",
       "      <td>-0.133904</td>\n",
       "      <td>-0.010444</td>\n",
       "      <td>0.529505</td>\n",
       "      <td>-0.065514</td>\n",
       "      <td>0.242299</td>\n",
       "      <td>0.174792</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007487</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.761158</td>\n",
       "      <td>0.081237</td>\n",
       "      <td>0.692522</td>\n",
       "      <td>0.761155</td>\n",
       "      <td>0.683748</td>\n",
       "      <td>0.191890</td>\n",
       "      <td>0.175768</td>\n",
       "      <td>0.251519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>sum</td>\n",
       "      <td>0.029485</td>\n",
       "      <td>0.039980</td>\n",
       "      <td>-0.007727</td>\n",
       "      <td>0.028095</td>\n",
       "      <td>-0.014384</td>\n",
       "      <td>-0.003393</td>\n",
       "      <td>0.140990</td>\n",
       "      <td>-0.015944</td>\n",
       "      <td>0.082661</td>\n",
       "      <td>0.052301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467080</td>\n",
       "      <td>0.761158</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040036</td>\n",
       "      <td>0.990328</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989078</td>\n",
       "      <td>0.433496</td>\n",
       "      <td>0.412584</td>\n",
       "      <td>0.089138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.948033</td>\n",
       "      <td>0.397434</td>\n",
       "      <td>-0.040787</td>\n",
       "      <td>0.046209</td>\n",
       "      <td>-0.025925</td>\n",
       "      <td>-0.006930</td>\n",
       "      <td>0.156551</td>\n",
       "      <td>-0.066261</td>\n",
       "      <td>0.134875</td>\n",
       "      <td>0.037885</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069601</td>\n",
       "      <td>0.081237</td>\n",
       "      <td>0.040036</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>0.040072</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>-0.008726</td>\n",
       "      <td>-0.049464</td>\n",
       "      <td>0.151090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>-0.005744</td>\n",
       "      <td>0.015105</td>\n",
       "      <td>-0.006523</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.000869</td>\n",
       "      <td>0.013826</td>\n",
       "      <td>0.001745</td>\n",
       "      <td>0.000808</td>\n",
       "      <td>0.008659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.526768</td>\n",
       "      <td>0.692522</td>\n",
       "      <td>0.990328</td>\n",
       "      <td>0.002397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.990328</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>0.498739</td>\n",
       "      <td>0.483796</td>\n",
       "      <td>0.005632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.029513</td>\n",
       "      <td>0.039961</td>\n",
       "      <td>-0.007726</td>\n",
       "      <td>0.028094</td>\n",
       "      <td>-0.014377</td>\n",
       "      <td>-0.003395</td>\n",
       "      <td>0.140985</td>\n",
       "      <td>-0.015942</td>\n",
       "      <td>0.082657</td>\n",
       "      <td>0.052299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.467078</td>\n",
       "      <td>0.761155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040072</td>\n",
       "      <td>0.990328</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.989078</td>\n",
       "      <td>0.433502</td>\n",
       "      <td>0.412589</td>\n",
       "      <td>0.089134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>-0.006551</td>\n",
       "      <td>-0.010256</td>\n",
       "      <td>0.017074</td>\n",
       "      <td>-0.008948</td>\n",
       "      <td>0.023335</td>\n",
       "      <td>0.001160</td>\n",
       "      <td>0.008935</td>\n",
       "      <td>0.003231</td>\n",
       "      <td>-0.007864</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>...</td>\n",
       "      <td>0.534223</td>\n",
       "      <td>0.683748</td>\n",
       "      <td>0.989078</td>\n",
       "      <td>-0.004919</td>\n",
       "      <td>0.999711</td>\n",
       "      <td>0.989078</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.489389</td>\n",
       "      <td>0.473626</td>\n",
       "      <td>-0.003215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>skew</td>\n",
       "      <td>0.017273</td>\n",
       "      <td>-0.102248</td>\n",
       "      <td>0.098780</td>\n",
       "      <td>-0.127144</td>\n",
       "      <td>0.125051</td>\n",
       "      <td>0.026778</td>\n",
       "      <td>-0.430413</td>\n",
       "      <td>0.050692</td>\n",
       "      <td>-0.250592</td>\n",
       "      <td>-0.157420</td>\n",
       "      <td>...</td>\n",
       "      <td>0.368651</td>\n",
       "      <td>0.191890</td>\n",
       "      <td>0.433496</td>\n",
       "      <td>-0.008726</td>\n",
       "      <td>0.498739</td>\n",
       "      <td>0.433502</td>\n",
       "      <td>0.489389</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>-0.251242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>kurt</td>\n",
       "      <td>-0.020697</td>\n",
       "      <td>-0.127670</td>\n",
       "      <td>0.097089</td>\n",
       "      <td>-0.134116</td>\n",
       "      <td>0.134626</td>\n",
       "      <td>0.025768</td>\n",
       "      <td>-0.475302</td>\n",
       "      <td>0.055928</td>\n",
       "      <td>-0.225901</td>\n",
       "      <td>-0.166785</td>\n",
       "      <td>...</td>\n",
       "      <td>0.362122</td>\n",
       "      <td>0.175768</td>\n",
       "      <td>0.412584</td>\n",
       "      <td>-0.049464</td>\n",
       "      <td>0.483796</td>\n",
       "      <td>0.412589</td>\n",
       "      <td>0.473626</td>\n",
       "      <td>0.976471</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.227585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>med</td>\n",
       "      <td>0.112493</td>\n",
       "      <td>0.181854</td>\n",
       "      <td>-0.173393</td>\n",
       "      <td>0.165843</td>\n",
       "      <td>-0.159833</td>\n",
       "      <td>-0.036435</td>\n",
       "      <td>0.471674</td>\n",
       "      <td>-0.084272</td>\n",
       "      <td>0.970705</td>\n",
       "      <td>0.195557</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197252</td>\n",
       "      <td>0.251519</td>\n",
       "      <td>0.089138</td>\n",
       "      <td>0.151090</td>\n",
       "      <td>0.005632</td>\n",
       "      <td>0.089134</td>\n",
       "      <td>-0.003215</td>\n",
       "      <td>-0.251242</td>\n",
       "      <td>-0.227585</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>37 rows  37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              city  city_development_index  company_type  \\\n",
       "city                      1.000000                0.326516      0.008261   \n",
       "city_development_index    0.326516                1.000000     -0.076021   \n",
       "company_type              0.008261               -0.076021      1.000000   \n",
       "education_level          -0.002657                0.037206     -0.194197   \n",
       "enrolled_university      -0.005467               -0.123983      0.124255   \n",
       "enrollee_id              -0.011282               -0.033675      0.036118   \n",
       "experience                0.096489                0.294039     -0.141304   \n",
       "gender                   -0.028777               -0.135284      0.070387   \n",
       "last_new_job              0.058492                0.175051     -0.205868   \n",
       "relevent_experience      -0.018078                0.062381     -0.343095   \n",
       "target                   -0.042851               -0.127290      0.090565   \n",
       "training_hours           -0.001281               -0.009960      0.016356   \n",
       "dum_100-500               0.020188                0.009460     -0.179839   \n",
       "dum_1000-4999             0.007163                0.058456     -0.135759   \n",
       "dum_10000+               -0.005784                0.060714     -0.210462   \n",
       "dum_10049                -0.006502               -0.028112     -0.106835   \n",
       "dum_5-10                 -0.008243               -0.016571     -0.091602   \n",
       "dum_50-99                -0.001613                0.017317     -0.212112   \n",
       "dum_500-999              -0.008541                0.005889     -0.103127   \n",
       "dum_5000-9999             0.009563                0.031192     -0.070107   \n",
       "dum_unknown              -0.005905               -0.089558      0.757133   \n",
       "dum_Arts                  0.019528                0.055948     -0.001131   \n",
       "dum_Business Degree       0.008899                0.029505     -0.030721   \n",
       "dum_Humanities            0.029599                0.081274     -0.001001   \n",
       "dum_No Major              0.008188                0.009186      0.237697   \n",
       "dum_Other                -0.002361                0.008300      0.009279   \n",
       "dum_STEM                 -0.027176               -0.070080     -0.195405   \n",
       "engineered_exp_training  -0.046996               -0.124718      0.101347   \n",
       "engineered_exp_training1  0.050736                0.152020     -0.060844   \n",
       "sum                       0.029485                0.039980     -0.007727   \n",
       "min                       0.948033                0.397434     -0.040787   \n",
       "max                       0.000116               -0.005744      0.015105   \n",
       "mean                      0.029513                0.039961     -0.007726   \n",
       "std                      -0.006551               -0.010256      0.017074   \n",
       "skew                      0.017273               -0.102248      0.098780   \n",
       "kurt                     -0.020697               -0.127670      0.097089   \n",
       "med                       0.112493                0.181854     -0.173393   \n",
       "\n",
       "                          education_level  enrolled_university  enrollee_id  \\\n",
       "city                            -0.002657            -0.005467    -0.011282   \n",
       "city_development_index           0.037206            -0.123983    -0.033675   \n",
       "company_type                    -0.194197             0.124255     0.036118   \n",
       "education_level                  1.000000            -0.092788    -0.017951   \n",
       "enrolled_university             -0.092788             1.000000     0.018923   \n",
       "enrollee_id                     -0.017951             0.018923     1.000000   \n",
       "experience                       0.251671            -0.264712    -0.028400   \n",
       "gender                          -0.075039             0.069155    -0.037870   \n",
       "last_new_job                     0.203493            -0.165547    -0.024685   \n",
       "relevent_experience              0.234385            -0.243483    -0.026482   \n",
       "target                           0.000267             0.063714     0.034132   \n",
       "training_hours                  -0.010150             0.024941     0.001209   \n",
       "dum_100-500                      0.065624            -0.059769    -0.021824   \n",
       "dum_1000-4999                    0.072420            -0.028987     0.001242   \n",
       "dum_10000+                       0.094248            -0.012975     0.020314   \n",
       "dum_10049                        0.012754             0.027423     0.006787   \n",
       "dum_5-10                        -0.000785             0.010082    -0.008009   \n",
       "dum_50-99                        0.057166            -0.048241    -0.010218   \n",
       "dum_500-999                      0.040895            -0.030522     0.001015   \n",
       "dum_5000-9999                    0.033963            -0.018704    -0.002995   \n",
       "dum_unknown                     -0.253906             0.116157     0.012442   \n",
       "dum_Arts                         0.015839            -0.027260     0.008120   \n",
       "dum_Business Degree              0.036759            -0.013590     0.006316   \n",
       "dum_Humanities                   0.083053            -0.058258     0.021302   \n",
       "dum_No Major                    -0.716364             0.098810    -0.003251   \n",
       "dum_Other                        0.043551            -0.021818     0.020341   \n",
       "dum_STEM                         0.544909            -0.040338    -0.017049   \n",
       "engineered_exp_training         -0.156325             0.139156     0.018136   \n",
       "engineered_exp_training1         0.138409            -0.133904    -0.010444   \n",
       "sum                              0.028095            -0.014384    -0.003393   \n",
       "min                              0.046209            -0.025925    -0.006930   \n",
       "max                             -0.006523             0.021277     0.000869   \n",
       "mean                             0.028094            -0.014377    -0.003395   \n",
       "std                             -0.008948             0.023335     0.001160   \n",
       "skew                            -0.127144             0.125051     0.026778   \n",
       "kurt                            -0.134116             0.134626     0.025768   \n",
       "med                              0.165843            -0.159833    -0.036435   \n",
       "\n",
       "                          experience    gender  last_new_job  \\\n",
       "city                        0.096489 -0.028777      0.058492   \n",
       "city_development_index      0.294039 -0.135284      0.175051   \n",
       "company_type               -0.141304  0.070387     -0.205868   \n",
       "education_level             0.251671 -0.075039      0.203493   \n",
       "enrolled_university        -0.264712  0.069155     -0.165547   \n",
       "enrollee_id                -0.028400 -0.037870     -0.024685   \n",
       "experience                  1.000000 -0.123199      0.466230   \n",
       "gender                     -0.123199  1.000000     -0.102991   \n",
       "last_new_job                0.466230 -0.102991      1.000000   \n",
       "relevent_experience         0.316400 -0.113295      0.236494   \n",
       "target                     -0.075269  0.029406     -0.032323   \n",
       "training_hours             -0.003184  0.003546     -0.006351   \n",
       "dum_100-500                 0.047184 -0.031314      0.062041   \n",
       "dum_1000-4999               0.071840 -0.015671      0.072702   \n",
       "dum_10000+                  0.064204 -0.011603      0.092561   \n",
       "dum_10049                  -0.028797 -0.017519      0.001777   \n",
       "dum_5-10                   -0.016161  0.001779     -0.013699   \n",
       "dum_50-99                   0.003641 -0.016128      0.024404   \n",
       "dum_500-999                 0.026732 -0.010730      0.026620   \n",
       "dum_5000-9999               0.030954 -0.008924      0.054125   \n",
       "dum_unknown                -0.128786  0.075263     -0.208687   \n",
       "dum_Arts                    0.000791 -0.003449      0.013491   \n",
       "dum_Business Degree         0.009262 -0.002940      0.021175   \n",
       "dum_Humanities              0.012673 -0.046066      0.028666   \n",
       "dum_No Major               -0.211713  0.078444     -0.206862   \n",
       "dum_Other                   0.003937 -0.002296      0.014891   \n",
       "dum_STEM                    0.170584 -0.044065      0.148980   \n",
       "engineered_exp_training    -0.376779  0.063815     -0.214083   \n",
       "engineered_exp_training1    0.529505 -0.065514      0.242299   \n",
       "sum                         0.140990 -0.015944      0.082661   \n",
       "min                         0.156551 -0.066261      0.134875   \n",
       "max                         0.013826  0.001745      0.000808   \n",
       "mean                        0.140985 -0.015942      0.082657   \n",
       "std                         0.008935  0.003231     -0.007864   \n",
       "skew                       -0.430413  0.050692     -0.250592   \n",
       "kurt                       -0.475302  0.055928     -0.225901   \n",
       "med                         0.471674 -0.084272      0.970705   \n",
       "\n",
       "                          relevent_experience  ...  engineered_exp_training  \\\n",
       "city                                -0.018078  ...                -0.046996   \n",
       "city_development_index               0.062381  ...                -0.124718   \n",
       "company_type                        -0.343095  ...                 0.101347   \n",
       "education_level                      0.234385  ...                -0.156325   \n",
       "enrolled_university                 -0.243483  ...                 0.139156   \n",
       "enrollee_id                         -0.026482  ...                 0.018136   \n",
       "experience                           0.316400  ...                -0.376779   \n",
       "gender                              -0.113295  ...                 0.063815   \n",
       "last_new_job                         0.236494  ...                -0.214083   \n",
       "relevent_experience                  1.000000  ...                -0.194672   \n",
       "target                              -0.072328  ...                 0.032656   \n",
       "training_hours                       0.005144  ...                 0.528059   \n",
       "dum_100-500                          0.120378  ...                -0.037741   \n",
       "dum_1000-4999                        0.049710  ...                -0.045642   \n",
       "dum_10000+                           0.059702  ...                -0.042426   \n",
       "dum_10049                            0.073906  ...                 0.015821   \n",
       "dum_5-10                             0.051203  ...                 0.015851   \n",
       "dum_50-99                            0.143629  ...                -0.020835   \n",
       "dum_500-999                          0.056579  ...                -0.020299   \n",
       "dum_5000-9999                        0.019917  ...                -0.013689   \n",
       "dum_unknown                         -0.403901  ...                 0.102540   \n",
       "dum_Arts                             0.009974  ...                 0.006372   \n",
       "dum_Business Degree                 -0.014636  ...                 0.008337   \n",
       "dum_Humanities                      -0.010090  ...                 0.006514   \n",
       "dum_No Major                        -0.316676  ...                 0.146475   \n",
       "dum_Other                           -0.002179  ...                -0.003965   \n",
       "dum_STEM                             0.276712  ...                -0.130666   \n",
       "engineered_exp_training             -0.194672  ...                 1.000000   \n",
       "engineered_exp_training1             0.174792  ...                -0.007487   \n",
       "sum                                  0.052301  ...                 0.467080   \n",
       "min                                  0.037885  ...                -0.069601   \n",
       "max                                  0.008659  ...                 0.526768   \n",
       "mean                                 0.052299  ...                 0.467078   \n",
       "std                                  0.005619  ...                 0.534223   \n",
       "skew                                -0.157420  ...                 0.368651   \n",
       "kurt                                -0.166785  ...                 0.362122   \n",
       "med                                  0.195557  ...                -0.197252   \n",
       "\n",
       "                          engineered_exp_training1       sum       min  \\\n",
       "city                                      0.050736  0.029485  0.948033   \n",
       "city_development_index                    0.152020  0.039980  0.397434   \n",
       "company_type                             -0.060844 -0.007727 -0.040787   \n",
       "education_level                           0.138409  0.028095  0.046209   \n",
       "enrolled_university                      -0.133904 -0.014384 -0.025925   \n",
       "enrollee_id                              -0.010444 -0.003393 -0.006930   \n",
       "experience                                0.529505  0.140990  0.156551   \n",
       "gender                                   -0.065514 -0.015944 -0.066261   \n",
       "last_new_job                              0.242299  0.082661  0.134875   \n",
       "relevent_experience                       0.174792  0.052301  0.037885   \n",
       "target                                   -0.045601 -0.016383 -0.051095   \n",
       "training_hours                            0.692075  0.989112  0.000137   \n",
       "dum_100-500                               0.004943 -0.006813  0.035074   \n",
       "dum_1000-4999                             0.032012 -0.004468  0.024437   \n",
       "dum_10000+                                0.021281 -0.005091  0.019055   \n",
       "dum_10049                                -0.006155  0.011209 -0.005779   \n",
       "dum_5-10                                  0.001195  0.008091 -0.009157   \n",
       "dum_50-99                                 0.015250  0.014615  0.013668   \n",
       "dum_500-999                               0.009055 -0.003378  0.000386   \n",
       "dum_5000-9999                             0.007908  0.004056  0.018314   \n",
       "dum_unknown                              -0.056109 -0.012288 -0.066960   \n",
       "dum_Arts                                 -0.009834 -0.007077  0.026923   \n",
       "dum_Business Degree                      -0.001049 -0.004334  0.017874   \n",
       "dum_Humanities                            0.005967  0.006053  0.044852   \n",
       "dum_No Major                             -0.115855 -0.027995 -0.042015   \n",
       "dum_Other                                 0.005558  0.000470  0.006932   \n",
       "dum_STEM                                  0.097314  0.024258  0.001289   \n",
       "engineered_exp_training                  -0.007487  0.467080 -0.069601   \n",
       "engineered_exp_training1                  1.000000  0.761158  0.081237   \n",
       "sum                                       0.761158  1.000000  0.040036   \n",
       "min                                       0.081237  0.040036  1.000000   \n",
       "max                                       0.692522  0.990328  0.002397   \n",
       "mean                                      0.761155  1.000000  0.040072   \n",
       "std                                       0.683748  0.989078 -0.004919   \n",
       "skew                                      0.191890  0.433496 -0.008726   \n",
       "kurt                                      0.175768  0.412584 -0.049464   \n",
       "med                                       0.251519  0.089138  0.151090   \n",
       "\n",
       "                               max      mean       std      skew      kurt  \\\n",
       "city                      0.000116  0.029513 -0.006551  0.017273 -0.020697   \n",
       "city_development_index   -0.005744  0.039961 -0.010256 -0.102248 -0.127670   \n",
       "company_type              0.015105 -0.007726  0.017074  0.098780  0.097089   \n",
       "education_level          -0.006523  0.028094 -0.008948 -0.127144 -0.134116   \n",
       "enrolled_university       0.021277 -0.014377  0.023335  0.125051  0.134626   \n",
       "enrollee_id               0.000869 -0.003395  0.001160  0.026778  0.025768   \n",
       "experience                0.013826  0.140985  0.008935 -0.430413 -0.475302   \n",
       "gender                    0.001745 -0.015942  0.003231  0.050692  0.055928   \n",
       "last_new_job              0.000808  0.082657 -0.007864 -0.250592 -0.225901   \n",
       "relevent_experience       0.008659  0.052299  0.005619 -0.157420 -0.166785   \n",
       "target                   -0.005414 -0.016378 -0.004552  0.032380  0.037553   \n",
       "training_hours            0.998778  0.989113  0.998511  0.501058  0.485772   \n",
       "dum_100-500              -0.014213 -0.006814 -0.014315 -0.056224 -0.057749   \n",
       "dum_1000-4999            -0.016124 -0.004469 -0.016917 -0.042636 -0.046992   \n",
       "dum_10000+               -0.014861 -0.005092 -0.015590 -0.051835 -0.050030   \n",
       "dum_10049                 0.014288  0.011209  0.014274  0.021528  0.023320   \n",
       "dum_5-10                  0.010113  0.008091  0.010168  0.011403  0.012250   \n",
       "dum_50-99                 0.013622  0.014617  0.012795  0.012249  0.012595   \n",
       "dum_500-999              -0.007621 -0.003378 -0.007846 -0.023448 -0.021442   \n",
       "dum_5000-9999            -0.000131  0.004053 -0.000679 -0.013262 -0.011002   \n",
       "dum_unknown               0.009224 -0.012287  0.011319  0.094574  0.093348   \n",
       "dum_Arts                 -0.008129 -0.007077 -0.008243 -0.003835  0.002102   \n",
       "dum_Business Degree      -0.005764 -0.004333 -0.005799  0.001869  0.001366   \n",
       "dum_Humanities            0.004016  0.006050  0.004076  0.001298  0.000519   \n",
       "dum_No Major              0.002216 -0.027995  0.004512  0.114483  0.116012   \n",
       "dum_Other                -0.000446  0.000471 -0.000696 -0.004635 -0.001311   \n",
       "dum_STEM                  0.000412  0.024259 -0.001451 -0.096207 -0.099649   \n",
       "engineered_exp_training   0.526768  0.467078  0.534223  0.368651  0.362122   \n",
       "engineered_exp_training1  0.692522  0.761155  0.683748  0.191890  0.175768   \n",
       "sum                       0.990328  1.000000  0.989078  0.433496  0.412584   \n",
       "min                       0.002397  0.040072 -0.004919 -0.008726 -0.049464   \n",
       "max                       1.000000  0.990328  0.999711  0.498739  0.483796   \n",
       "mean                      0.990328  1.000000  0.989078  0.433502  0.412589   \n",
       "std                       0.999711  0.989078  1.000000  0.489389  0.473626   \n",
       "skew                      0.498739  0.433502  0.489389  1.000000  0.976471   \n",
       "kurt                      0.483796  0.412589  0.473626  0.976471  1.000000   \n",
       "med                       0.005632  0.089134 -0.003215 -0.251242 -0.227585   \n",
       "\n",
       "                               med  \n",
       "city                      0.112493  \n",
       "city_development_index    0.181854  \n",
       "company_type             -0.173393  \n",
       "education_level           0.165843  \n",
       "enrolled_university      -0.159833  \n",
       "enrollee_id              -0.036435  \n",
       "experience                0.471674  \n",
       "gender                   -0.084272  \n",
       "last_new_job              0.970705  \n",
       "relevent_experience       0.195557  \n",
       "target                   -0.037498  \n",
       "training_hours           -0.000597  \n",
       "dum_100-500               0.050385  \n",
       "dum_1000-4999             0.066451  \n",
       "dum_10000+                0.083445  \n",
       "dum_10049                -0.008023  \n",
       "dum_5-10                 -0.019344  \n",
       "dum_50-99                 0.008080  \n",
       "dum_500-999               0.020533  \n",
       "dum_5000-9999             0.050101  \n",
       "dum_unknown              -0.161101  \n",
       "dum_Arts                  0.011122  \n",
       "dum_Business Degree       0.014634  \n",
       "dum_Humanities            0.019189  \n",
       "dum_No Major             -0.162239  \n",
       "dum_Other                 0.009726  \n",
       "dum_STEM                  0.119354  \n",
       "engineered_exp_training  -0.197252  \n",
       "engineered_exp_training1  0.251519  \n",
       "sum                       0.089138  \n",
       "min                       0.151090  \n",
       "max                       0.005632  \n",
       "mean                      0.089134  \n",
       "std                      -0.003215  \n",
       "skew                     -0.251242  \n",
       "kurt                     -0.227585  \n",
       "med                       1.000000  \n",
       "\n",
       "[37 rows x 37 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrc=LogisticRegression()\n",
    "lrc.fit(full_train_x,full_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  77 tasks      | elapsed:  3.9min\n",
      "[Parallel(n_jobs=-1)]: Done 335 tasks      | elapsed: 19.4min\n",
      "[Parallel(n_jobs=-1)]: Done 1030 tasks      | elapsed: 34.7min\n",
      "[Parallel(n_jobs=-1)]: Done 1920 out of 1920 | elapsed: 43.1min finished\n",
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=LogisticRegression(C=1.0, class_weight='balanced',\n",
       "                                          dual=False, fit_intercept=True,\n",
       "                                          intercept_scaling=1, l1_ratio=None,\n",
       "                                          max_iter=100, multi_class='auto',\n",
       "                                          n_jobs=None, penalty='l2',\n",
       "                                          random_state=None, solver='lbfgs',\n",
       "                                          tol=0.0001, verbose=0,\n",
       "                                          warm_start=False),\n",
       "             iid='deprecated', n_jobs=-1,\n",
       "             param_grid={'C': [1.0, 0.01], 'dual': [False, True],\n",
       "                         'fit_intercept': [True, False],\n",
       "                         'max_iter': [100, 1000],\n",
       "                         'penalty': ['l2', 'l1', 'elasticnet'],\n",
       "                         'random_state': [42, 71],\n",
       "                         'solver': ['lbfgs', 'liblinear'],\n",
       "                         'tol': [0.0001, 0.001]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=-2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrc=LogisticRegression(C= 1.0,\n",
    "  dual= True,\n",
    "  fit_intercept= True,\n",
    "  max_iter= 100,\n",
    "  penalty='l2',\n",
    "  random_state= 71,\n",
    "  solver='liblinear',tol= 0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\umairansari\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:947: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "lrc.fit(full_train_x,full_train_y)\n",
    "predicted_final_lrc_hyp=lrc.predict(test_final)\n",
    "#print(classification_report(predicted_final_lrc,validation_y))\n",
    "prediction=pd.DataFrame({'enrollee_id':test[\"enrollee_id\"],'target':predicted_final_lrc_hyp})\n",
    "prediction.to_csv('predicted1_lrc_bal_standardscaler_hyp.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(LogisticRegression(C=1.0, class_weight='balanced', dual=True,\n",
       "                    fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                    max_iter=100, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                    random_state=71, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                    warm_start=False),\n",
       " {'C': 1.0,\n",
       "  'dual': True,\n",
       "  'fit_intercept': True,\n",
       "  'max_iter': 100,\n",
       "  'penalty': 'l2',\n",
       "  'random_state': 71,\n",
       "  'solver': 'liblinear',\n",
       "  'tol': 0.0001},\n",
       " 0.8661147194432723)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gcv.best_estimator_,gcv.best_params_,gcv.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_dict={\n",
    "            'eps':[0.001,.01], \n",
    "            'l1_ratio':[0.5,0.1],\n",
    "            'max_iter':[100,1000], \n",
    "            'n_alphas':[100,500],\n",
    "            'normalize':[True,False],\n",
    "            'selection':['cyclic','random'], \n",
    "            'tol':[0.0001,.001]\n",
    "}\n",
    "gcv=RandomizedSearchCV(ElasticNetCV(),param_grid=param_dict,cv=2,n_jobs=-1,verbose=-2)\n",
    "gcv.fit(full_train_x,full_train_y)\n",
    "gcv.best_params_,gcv.best_score_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
