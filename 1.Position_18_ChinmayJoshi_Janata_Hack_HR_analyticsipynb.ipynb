{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as st\n",
    "from sklearn.model_selection import train_test_split,KFold,StratifiedKFold,GridSearchCV,RandomizedSearchCV,cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,GradientBoostingClassifier,RandomForestRegressor,BaggingRegressor,AdaBoostRegressor,GradientBoostingRegressor\n",
    "from sklearn.linear_model import LinearRegression,LogisticRegression,Lasso, Ridge\n",
    "from sklearn.tree import DecisionTreeClassifier,DecisionTreeRegressor\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import r2_score,roc_auc_score,classification_report,mean_squared_error,accuracy_score,confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('D:/datasets+minipro/analytics vidhya datasets/janata hack p3 hr analytics/train.csv')\n",
    "dfte=pd.read_csv('D:/datasets+minipro/analytics vidhya datasets/janata hack p3 hr analytics/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "enrollee_id                  0\n",
       "city                         0\n",
       "city_development_index       0\n",
       "gender                    4098\n",
       "relevent_experience          0\n",
       "enrolled_university        342\n",
       "education_level            457\n",
       "major_discipline          2838\n",
       "experience                  59\n",
       "company_size              4779\n",
       "company_type              5039\n",
       "last_new_job               367\n",
       "training_hours               0\n",
       "target                       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.copy() # backup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Work on copy df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.drop(['enrollee_id','city'],1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Male      12884\n",
       "Female     1188\n",
       "Other       189\n",
       "Name: gender, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender feature imputed with mode & converted to categorical\n",
    "df1['gender']=df1['gender'].map({'Male':1,'Female':0,'Other':2})\n",
    "df1['gender']=df1['gender'].fillna(1).astype('int')\n",
    "\n",
    "# enrolled_university feature imputed with mode & converted to categorical \n",
    "df1['enrolled_university']=df1['enrolled_university'].fillna('no_enrollment')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "df1['enrolled_university']=le.fit_transform(df1['enrolled_university'])\n",
    "\n",
    "df1['education_level']=df1['education_level'].fillna('Graduate')\n",
    "df1['education_level']=le.fit_transform(df1['education_level'])\n",
    "\n",
    "df1['major_discipline']=df1['major_discipline'].fillna('STEM')\n",
    "df1['major_discipline']=le.fit_transform(df1['major_discipline'])\n",
    "\n",
    "df1['experience'].replace({'<1':'1','>20':'20'},inplace=True)\n",
    "df1['experience']=df1['experience'].fillna('20')\n",
    "df1['experience']=df1['experience'].astype('int')\n",
    "\n",
    "df1['company_size'].replace({'<10':'10','10/49':'30','50-99':'75','100-500':'300','500-999':'750',\n",
    "                            '1000-4999':'3000','5000-9999':'7500','10000+':'10000'},inplace=True)\n",
    "\n",
    "df1['company_size']=df1['company_size'].fillna('75')\n",
    "df1['company_size']=df1['company_size'].astype('int')\n",
    "\n",
    "df1['last_new_job'].replace({'>4':4,'never':0},inplace=True)\n",
    "\n",
    "df1['last_new_job']=df1['last_new_job'].fillna(1)\n",
    "\n",
    "df1['last_new_job']=df1['last_new_job'].astype('int')\n",
    "\n",
    "df1['company_type']=df1['company_type'].fillna('Pvt Ltd')\n",
    "df1['company_type']=le.fit_transform(df1['company_type'])\n",
    "\n",
    "df1['relevent_experience']=le.fit_transform(df1['relevent_experience'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    86.79122\n",
       "1    13.20878\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1['target'].value_counts(normalize=True)*100# Imbalanced dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets try without any over sampling,undersampling or SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>training</th>\n",
       "      <th>testing</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ada boost</td>\n",
       "      <td>0.639299</td>\n",
       "      <td>0.867298</td>\n",
       "      <td>0.870643</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.591168</td>\n",
       "      <td>0.998230</td>\n",
       "      <td>0.862745</td>\n",
       "      <td>0.206897</td>\n",
       "      <td>0.025532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bagged LR</td>\n",
       "      <td>0.589443</td>\n",
       "      <td>0.866889</td>\n",
       "      <td>0.872004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive-Bayes</td>\n",
       "      <td>0.588875</td>\n",
       "      <td>0.850344</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.267857</td>\n",
       "      <td>0.063830</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.584952</td>\n",
       "      <td>0.866889</td>\n",
       "      <td>0.872004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.544813</td>\n",
       "      <td>0.978144</td>\n",
       "      <td>0.854575</td>\n",
       "      <td>0.214286</td>\n",
       "      <td>0.051064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.528065</td>\n",
       "      <td>0.873834</td>\n",
       "      <td>0.857843</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.027660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Decistion Tree</td>\n",
       "      <td>0.518036</td>\n",
       "      <td>0.998298</td>\n",
       "      <td>0.766612</td>\n",
       "      <td>0.152603</td>\n",
       "      <td>0.180851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 names  auc_score  training   testing  precision    recall\n",
       "0            Ada boost   0.639299  0.867298  0.870643   0.000000  0.000000\n",
       "1        Random Forest   0.591168  0.998230  0.862745   0.206897  0.025532\n",
       "2            bagged LR   0.589443  0.866889  0.872004   0.000000  0.000000\n",
       "3          Naive-Bayes   0.588875  0.850344  0.857843   0.267857  0.063830\n",
       "4  Logistic Regression   0.584952  0.866889  0.872004   0.000000  0.000000\n",
       "5              Bagging   0.544813  0.978144  0.854575   0.214286  0.051064\n",
       "6                  KNN   0.528065  0.873834  0.857843   0.166667  0.027660\n",
       "7       Decistion Tree   0.518036  0.998298  0.766612   0.152603  0.180851"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set seed for same results everytime\n",
    "seed=0\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X=df1.drop('target',1)\n",
    "y=df1['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state =1)\n",
    "\n",
    "#declare the models\n",
    "lr = LogisticRegression()\n",
    "rf=RandomForestClassifier()\n",
    "adb=ensemble.AdaBoostClassifier()\n",
    "bgc=ensemble.BaggingClassifier()\n",
    "gnb = GaussianNB()\n",
    "knn=KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "# ab_rf = AdaBoostClassifier(base_estimator=rf,random_state=0)\n",
    "# ab_dt = AdaBoostClassifier(base_estimator=dt,random_state=0)\n",
    "# ab_nb=  AdaBoostClassifier(base_estimator=gnb,random_state=0)\n",
    "# ab_lr=  AdaBoostClassifier(base_estimator=lr,random_state=0)\n",
    "bgcl_lr = BaggingClassifier(base_estimator=lr, random_state=0)\n",
    "\n",
    "# ,ab_rf,ab_dt,ab_nb,ab_lr,bgcl_lr\n",
    "\n",
    "models=[lr,rf,adb,bgc,gnb,knn,dt,bgcl_lr]\n",
    "sctr,scte,auc,ps,rs=[],[],[],[],[]\n",
    "def ens(X_train,X_test, y_train, y_test):\n",
    "    for model in models:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            y_test_pred_new=model.predict_proba(X_test)\n",
    "            y_test_pred_new=y_test_pred_new[:,1]\n",
    "            train_score=model.score(X_train,y_train)\n",
    "            test_score=model.score(X_test,y_test)\n",
    "            p_score=metrics.precision_score(y_test,y_test_pred)\n",
    "            r_score=metrics.recall_score(y_test,y_test_pred)\n",
    "            \n",
    "            ac=metrics.roc_auc_score(y_test,y_test_pred_new)\n",
    "            \n",
    "            sctr.append(train_score)\n",
    "            scte.append(test_score)\n",
    "            ps.append(p_score)\n",
    "            rs.append(r_score)\n",
    "            auc.append(ac)\n",
    "    return sctr,scte,auc,ps,rs\n",
    "ens(X_train,X_test, y_train, y_test)\n",
    "# 'ab_rf','ab_dt','ab_nb','ab_lr','bgcl_lr'\n",
    "ensemble=pd.DataFrame({'names':['Logistic Regression','Random Forest','Ada boost','Bagging',\n",
    "                                'Naive-Bayes','KNN','Decistion Tree',\n",
    "                                'bagged LR'],\n",
    "                       'auc_score':auc,'training':sctr,'testing':scte,'precision':ps,'recall':rs})\n",
    "ensemble=ensemble.sort_values(by='auc_score',ascending=False).reset_index(drop=True)\n",
    "ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=dfte.copy() ## backup of dfte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df2.drop(['city','enrollee_id'],1,inplace=True)\n",
    "\n",
    "# Gender feature imputed with mode & converted to categorical\n",
    "df2['gender']=df2['gender'].map({'Male':1,'Female':0,'Other':2})\n",
    "df2['gender']=df2['gender'].fillna(1).astype('int')\n",
    "\n",
    "# enrolled_university feature imputed with mode & converted to categorical \n",
    "df2['enrolled_university']=df2['enrolled_university'].fillna('no_enrollment')\n",
    "df2['enrolled_university']=le.fit_transform(df2['enrolled_university'])\n",
    "\n",
    "df2['education_level']=df2['education_level'].fillna('Graduate')\n",
    "df2['education_level']=le.fit_transform(df2['education_level'])\n",
    "\n",
    "df2['major_discipline']=df2['major_discipline'].fillna('STEM')\n",
    "df2['major_discipline']=le.fit_transform(df2['major_discipline'])\n",
    "\n",
    "df2['experience'].replace({'<1':'1','>20':'20'},inplace=True)\n",
    "df2['experience']=df2['experience'].fillna('20')\n",
    "df2['experience']=df2['experience'].astype('int')\n",
    "\n",
    "df2['company_size'].replace({'<10':'10','10/49':'30','50-99':'75','100-500':'300','500-999':'750',\n",
    "                            '1000-4999':'3000','5000-9999':'7500','10000+':'10000'},inplace=True)\n",
    "\n",
    "df2['company_size']=df2['company_size'].fillna('75')\n",
    "df2['company_size']=df2['company_size'].astype('int')\n",
    "\n",
    "df2['last_new_job'].replace({'>4':4,'never':0},inplace=True)\n",
    "\n",
    "df2['last_new_job']=df2['last_new_job'].fillna(1)\n",
    "\n",
    "df2['last_new_job']=df2['last_new_job'].astype('int')\n",
    "\n",
    "df2['company_type']=df2['company_type'].fillna('Pvt Ltd')\n",
    "df2['company_type']=le.fit_transform(df2['company_type'])\n",
    "\n",
    "df2['relevent_experience']=le.fit_transform(df2['relevent_experience'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Making predictions:\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "adb=AdaBoostClassifier()\n",
    "\n",
    "adb.fit(X,y)\n",
    "y_test_pred_adb=adb.predict_proba(df2)[:,1]\n",
    "finalpred=pd.concat([dfte['enrollee_id'],pd.DataFrame(y_test_pred_adb,columns=['target'])],1)\n",
    "finalpred.to_csv(\"D:/datasets+minipro/analytics vidhya datasets/janata hack p3 hr analytics/adbpred.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SMOTE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "oversample = SMOTE()\n",
    "X_smote, y_smote = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>auc_score</th>\n",
       "      <th>training</th>\n",
       "      <th>testing</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.921682</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>0.848761</td>\n",
       "      <td>0.840810</td>\n",
       "      <td>0.856282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bagging</td>\n",
       "      <td>0.919451</td>\n",
       "      <td>0.988429</td>\n",
       "      <td>0.860056</td>\n",
       "      <td>0.876667</td>\n",
       "      <td>0.834391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.866786</td>\n",
       "      <td>0.858712</td>\n",
       "      <td>0.771729</td>\n",
       "      <td>0.707305</td>\n",
       "      <td>0.918464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ada boost</td>\n",
       "      <td>0.811116</td>\n",
       "      <td>0.738331</td>\n",
       "      <td>0.730311</td>\n",
       "      <td>0.720123</td>\n",
       "      <td>0.743655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decistion Tree</td>\n",
       "      <td>0.807264</td>\n",
       "      <td>0.998588</td>\n",
       "      <td>0.806715</td>\n",
       "      <td>0.792505</td>\n",
       "      <td>0.825190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive-Bayes</td>\n",
       "      <td>0.672831</td>\n",
       "      <td>0.623794</td>\n",
       "      <td>0.617352</td>\n",
       "      <td>0.607736</td>\n",
       "      <td>0.638008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bagged LR</td>\n",
       "      <td>0.661305</td>\n",
       "      <td>0.611438</td>\n",
       "      <td>0.608566</td>\n",
       "      <td>0.601483</td>\n",
       "      <td>0.617703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.659812</td>\n",
       "      <td>0.607947</td>\n",
       "      <td>0.602918</td>\n",
       "      <td>0.595100</td>\n",
       "      <td>0.616434</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 names  auc_score  training   testing  precision    recall\n",
       "0        Random Forest   0.921682  0.998588  0.848761   0.840810  0.856282\n",
       "1              Bagging   0.919451  0.988429  0.860056   0.876667  0.834391\n",
       "2                  KNN   0.866786  0.858712  0.771729   0.707305  0.918464\n",
       "3            Ada boost   0.811116  0.738331  0.730311   0.720123  0.743655\n",
       "4       Decistion Tree   0.807264  0.998588  0.806715   0.792505  0.825190\n",
       "5          Naive-Bayes   0.672831  0.623794  0.617352   0.607736  0.638008\n",
       "6            bagged LR   0.661305  0.611438  0.608566   0.601483  0.617703\n",
       "7  Logistic Regression   0.659812  0.607947  0.602918   0.595100  0.616434"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set seed for same results everytime\n",
    "seed=0\n",
    "import sklearn.ensemble as ensemble\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "X=X_smote\n",
    "y=y_smote\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state =1)\n",
    "\n",
    "#declare the models\n",
    "lr = LogisticRegression()\n",
    "rf=RandomForestClassifier()\n",
    "adb=ensemble.AdaBoostClassifier()\n",
    "bgc=ensemble.BaggingClassifier()\n",
    "gnb = GaussianNB()\n",
    "knn=KNeighborsClassifier()\n",
    "dt = DecisionTreeClassifier()\n",
    "# ab_rf = AdaBoostClassifier(base_estimator=rf,random_state=0)\n",
    "# ab_dt = AdaBoostClassifier(base_estimator=dt,random_state=0)\n",
    "# ab_nb=  AdaBoostClassifier(base_estimator=gnb,random_state=0)\n",
    "# ab_lr=  AdaBoostClassifier(base_estimator=lr,random_state=0)\n",
    "bgcl_lr = BaggingClassifier(base_estimator=lr, random_state=0)\n",
    "\n",
    "# ,ab_rf,ab_dt,ab_nb,ab_lr,bgcl_lr\n",
    "\n",
    "models=[lr,rf,adb,bgc,gnb,knn,dt,bgcl_lr]\n",
    "sctr,scte,auc,ps,rs=[],[],[],[],[]\n",
    "def ens(X_train,X_test, y_train, y_test):\n",
    "    for model in models:\n",
    "            model.fit(X_train, y_train)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "            y_test_pred_new=model.predict_proba(X_test)\n",
    "            y_test_pred_new=y_test_pred_new[:,1]\n",
    "            train_score=model.score(X_train,y_train)\n",
    "            test_score=model.score(X_test,y_test)\n",
    "            p_score=metrics.precision_score(y_test,y_test_pred)\n",
    "            r_score=metrics.recall_score(y_test,y_test_pred)\n",
    "            \n",
    "            ac=metrics.roc_auc_score(y_test,y_test_pred_new)\n",
    "            \n",
    "            sctr.append(train_score)\n",
    "            scte.append(test_score)\n",
    "            ps.append(p_score)\n",
    "            rs.append(r_score)\n",
    "            auc.append(ac)\n",
    "    return sctr,scte,auc,ps,rs\n",
    "ens(X_train,X_test, y_train, y_test)\n",
    "# 'ab_rf','ab_dt','ab_nb','ab_lr','bgcl_lr'\n",
    "ensemble=pd.DataFrame({'names':['Logistic Regression','Random Forest','Ada boost','Bagging',\n",
    "                                'Naive-Bayes','KNN','Decistion Tree',\n",
    "                                'bagged LR'],\n",
    "                       'auc_score':auc,'training':sctr,'testing':scte,'precision':ps,'recall':rs})\n",
    "ensemble=ensemble.sort_values(by='auc_score',ascending=False).reset_index(drop=True)\n",
    "ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf=RandomForestClassifier()\n",
    "\n",
    "rf.fit(X_smote,y_smote)\n",
    "\n",
    "y_test_pred_rf=rf.predict_proba(df2)[:,1]\n",
    "finalpred=pd.concat([dfte['enrollee_id'],pd.DataFrame(y_test_pred_rf,columns=['target'])],1)\n",
    "finalpred.to_csv(\"D:/datasets+minipro/analytics vidhya datasets/janata hack p3 hr analytics/rfpred.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'min_samples_leaf': 6, 'max_depth': 9, 'criterion': 'gini'}\n"
     ]
    }
   ],
   "source": [
    "X=X_smote\n",
    "y=y_smote\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state =0)\n",
    "from sklearn.model_selection import GridSearchCV,RandomizedSearchCV\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt_params = {'max_depth':np.arange(1,10), 'min_samples_leaf':np.arange(2,30), 'criterion':['entropy','gini']}\n",
    "rscv = RandomizedSearchCV(dt, dt_params, cv=5, scoring='roc_auc')\n",
    "rscv.fit(X, y)\n",
    "print(rscv.best_params_)\n",
    "rscv_best_DT=rscv.best_params_\n",
    "\n",
    "DT=DecisionTreeClassifier(**rscv_best_DT)\n",
    "DT.fit(X_smote,y_smote)\n",
    "y_test_pred_DT=DT.predict_proba(df2)[:,1]\n",
    "finalpred=pd.concat([dfte['enrollee_id'],pd.DataFrame(y_test_pred_DT,columns=['target'])],1)\n",
    "finalpred.to_csv(\"D:/datasets+minipro/analytics vidhya datasets/janata hack p3 hr analytics/DTpred.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# XGB classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb=XGBClassifier(learning_rate=0.09,n_estimators=125,max_depth=4,min_child_weight=4,colsample_bytree=0.5,reg_alpha=0.000001 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X_smote,y_smote)\n",
    "y_test_pred_xgb=xgb.predict_proba(df2)[:,1]\n",
    "finalpred=pd.concat([dfte['enrollee_id'],pd.DataFrame(y_test_pred_xgb,columns=['target'])],1)\n",
    "finalpred.to_csv(\"D:/datasets+minipro/analytics vidhya datasets/janata hack p3 hr analytics/xgbpred.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# using get_dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3=df.copy() # backup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe=OneHotEncoder(sparse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3['enrolled_university'].fillna('no_enrollment',inplace=True)\n",
    "df3['last_new_job'].fillna('1',inplace=True)\n",
    "df3['education_level'].fillna('Graduate',inplace=True)\n",
    "df3['experience'].fillna('>20',inplace=True)\n",
    "\n",
    "more=['gender','company_size','company_type','major_discipline'] \n",
    "#more is for features having missing values greater than 15%\n",
    "for i in range(len(more)):\n",
    "    df3[more[i]].fillna('missing',axis=0,inplace=True)\n",
    "\n",
    "df3.drop(['enrollee_id','city'],1,inplace=True)\n",
    "\n",
    "df3['experience'].replace({'<1':'1','>20':'21'},inplace=True)\n",
    "df3['company_size'].replace({'<10':'10','10/49':'30','50-99':'75','100-500':'300','500-999':'750',\n",
    "                            '1000-4999':'3000','5000-9999':'7500','10000+':'10000'},inplace=True)\n",
    "df3['last_new_job'].replace({'>4':5,'never':0},inplace=True)\n",
    "\n",
    "df3=pd.get_dummies(data=df3,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=dfte.copy() # backup of test data is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['enrolled_university'].fillna('no_enrollment',inplace=True)\n",
    "df4['last_new_job'].fillna('1',inplace=True)\n",
    "df4['education_level'].fillna('Graduate',inplace=True)\n",
    "df4['experience'].fillna('>20',inplace=True)\n",
    "\n",
    "more=['gender','company_size','company_type','major_discipline'] \n",
    "#more is for features having missing values greater than 15%\n",
    "for i in range(len(more)):\n",
    "    df4[more[i]].fillna('missing',axis=0,inplace=True)\n",
    "    \n",
    "df4.drop(['enrollee_id','city'],1,inplace=True)\n",
    "df4['experience'].replace({'<1':'1','>20':'21'},inplace=True)\n",
    "df4['company_size'].replace({'<10':'10','10/49':'30','50-99':'75','100-500':'300','500-999':'750',\n",
    "                            '1000-4999':'3000','5000-9999':'7500','10000+':'10000'},inplace=True)\n",
    "df4['last_new_job'].replace({'>4':5,'never':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4=pd.get_dummies(data=df4,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15021, 57)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df3.drop('target',1)\n",
    "y=df3['target']\n",
    "X_smote1, y_smote1 = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set seed for same results everytime\n",
    "# seed=0\n",
    "# import sklearn.ensemble as ensemble\n",
    "# import sklearn.metrics as metrics\n",
    "\n",
    "# X=X_smote1\n",
    "# y=y_smote1\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.2, random_state =1)\n",
    "\n",
    "# #declare the models\n",
    "# lr = LogisticRegression()\n",
    "# rf=RandomForestClassifier()\n",
    "# adb=ensemble.AdaBoostClassifier()\n",
    "# bgc=ensemble.BaggingClassifier()\n",
    "# gnb = GaussianNB()\n",
    "# knn=KNeighborsClassifier()\n",
    "# dt = DecisionTreeClassifier()\n",
    "# # ab_rf = AdaBoostClassifier(base_estimator=rf,random_state=0)\n",
    "# # ab_dt = AdaBoostClassifier(base_estimator=dt,random_state=0)\n",
    "# # ab_nb=  AdaBoostClassifier(base_estimator=gnb,random_state=0)\n",
    "# # ab_lr=  AdaBoostClassifier(base_estimator=lr,random_state=0)\n",
    "# bgcl_lr = BaggingClassifier(base_estimator=lr, random_state=0)\n",
    "\n",
    "# # ,ab_rf,ab_dt,ab_nb,ab_lr,bgcl_lr\n",
    "\n",
    "# models=[lr,rf,adb,bgc,gnb,knn,dt,bgcl_lr]\n",
    "# sctr,scte,auc,ps,rs=[],[],[],[],[]\n",
    "# def ens(X_train,X_test, y_train, y_test):\n",
    "#     for model in models:\n",
    "#             model.fit(X_train, y_train)\n",
    "#             y_test_pred = model.predict(X_test)\n",
    "#             y_test_pred_new=model.predict_proba(X_test)\n",
    "#             y_test_pred_new=y_test_pred_new[:,1]\n",
    "#             train_score=model.score(X_train,y_train)\n",
    "#             test_score=model.score(X_test,y_test)\n",
    "#             p_score=metrics.precision_score(y_test,y_test_pred)\n",
    "#             r_score=metrics.recall_score(y_test,y_test_pred)\n",
    "            \n",
    "#             ac=metrics.roc_auc_score(y_test,y_test_pred_new)\n",
    "            \n",
    "#             sctr.append(train_score)\n",
    "#             scte.append(test_score)\n",
    "#             ps.append(p_score)\n",
    "#             rs.append(r_score)\n",
    "#             auc.append(ac)\n",
    "#     return sctr,scte,auc,ps,rs\n",
    "# ens(X_train,X_test, y_train, y_test)\n",
    "# # 'ab_rf','ab_dt','ab_nb','ab_lr','bgcl_lr'\n",
    "# ensemble=pd.DataFrame({'names':['Logistic Regression','Random Forest','Ada boost','Bagging',\n",
    "#                                 'Naive-Bayes','KNN','Decistion Tree',\n",
    "#                                 'bagged LR'],\n",
    "#                        'auc_score':auc,'training':sctr,'testing':scte,'precision':ps,'recall':rs})\n",
    "# ensemble=ensemble.sort_values(by='auc_score',ascending=False).reset_index(drop=True)\n",
    "# ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X_smote1,y_smote1)\n",
    "y_test_pred_xgb=xgb.predict_proba(df4)[:,1]\n",
    "finalpred=pd.concat([dfte['enrollee_id'],pd.DataFrame(y_test_pred_xgb,columns=['target'])],1)\n",
    "finalpred.to_csv(\"D:/datasets+minipro/analytics vidhya datasets/janata hack p3 hr analytics/xgbpred.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# combination of LE & ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df.copy() # backup\n",
    "\n",
    "df5['enrolled_university'].fillna('no_enrollment',inplace=True)\n",
    "df5['last_new_job'].fillna('1',inplace=True)\n",
    "df5['education_level'].fillna('Graduate',inplace=True)\n",
    "df5['experience'].fillna('>20',inplace=True)\n",
    "\n",
    "more=['gender','company_size','company_type','major_discipline'] \n",
    "#more is for features having missing values greater than 15%\n",
    "for i in range(len(more)):\n",
    "    df5[more[i]].fillna('missing',axis=0,inplace=True)\n",
    "\n",
    "df5.drop(['enrollee_id','city'],1,inplace=True)\n",
    "\n",
    "df5['experience'].replace({'<1':'0','>20':'21'},inplace=True)\n",
    "df5['company_size'].replace({'<10':'10','10/49':'30','50-99':'75','100-500':'300','500-999':'750',\n",
    "                            '1000-4999':'3000','5000-9999':'7500','10000+':'10000'},inplace=True)\n",
    "df5['last_new_job'].replace({'>4':5,'never':0},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df5['enrolled_university'].replace({'no_enrollment':0,'Part time course':1,'Full time course':2},inplace=True)\n",
    "\n",
    "df5['relevent_experience'].replace({'No relevent experience':0,'Has relevent experience':1},inplace=True)\n",
    "\n",
    "df5['company_size'].replace({'missing':75},inplace=True)\n",
    "\n",
    "df5['company_size']=df5['company_size'].astype('int')\n",
    "\n",
    "df5['company_size']=df5.groupby('company_type').company_size.apply(lambda x:x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=pd.get_dummies(data=df5,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df6=dfte.copy() # backup of test data is used\n",
    "\n",
    "df6['enrolled_university'].fillna('no_enrollment',inplace=True)\n",
    "df6['last_new_job'].fillna('1',inplace=True)\n",
    "df6['education_level'].fillna('Graduate',inplace=True)\n",
    "df6['experience'].fillna('>20',inplace=True)\n",
    "\n",
    "more=['gender','company_size','company_type','major_discipline'] \n",
    "#more is for features having missing values greater than 15%\n",
    "for i in range(len(more)):\n",
    "    df6[more[i]].fillna('missing',axis=0,inplace=True)\n",
    "    \n",
    "df6.drop(['enrollee_id','city'],1,inplace=True)\n",
    "df6['experience'].replace({'<1':'0','>20':'21'},inplace=True)\n",
    "df6['company_size'].replace({'<10':'10','10/49':'30','50-99':'75','100-500':'300','500-999':'750',\n",
    "                            '1000-4999':'3000','5000-9999':'7500','10000+':'10000'},inplace=True)\n",
    "df6['last_new_job'].replace({'>4':5,'never':0},inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6['enrolled_university'].replace({'no_enrollment':0,'Part time course':1,'Full time course':2},inplace=True)\n",
    "\n",
    "df6['relevent_experience'].replace({'No relevent experience':0,'Has relevent experience':1},inplace=True)\n",
    "\n",
    "df6['company_size'].replace({'missing':75},inplace=True)\n",
    "\n",
    "df6['company_size']=df6['company_size'].astype('int')\n",
    "\n",
    "df6['company_size']=df6.groupby('company_type').company_size.apply(lambda x:x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6=pd.get_dummies(data=df6,drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=df5.drop('target',1)\n",
    "y=df5['target']\n",
    "# X_smote2, y_smote2 = oversample.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This above setting which for df5 and df6 is a combination of label encoding and get_dummies is giving best accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best accuracy with xgb classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#               colsample_bynode=1, colsample_bytree=0.5, gamma=0,\n",
    "#               learning_rate=0.09, max_delta_step=0, max_depth=4,\n",
    "#               min_child_weight=4, missing=None, n_estimators=125, n_jobs=1,\n",
    "#               nthread=None, objective='binary:logistic', random_state=0,\n",
    "#               reg_alpha=1e-06, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
    "#               silent=None, subsample=1, verbosity=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X,y)\n",
    "y_test_pred_xgb=xgb.predict_proba(df6)[:,1]\n",
    "finalpred=pd.concat([dfte['enrollee_id'],pd.DataFrame(y_test_pred_xgb,columns=['target'])],1)\n",
    "finalpred.to_csv(\"D:/datasets+minipro/analytics vidhya datasets/janata hack p3 hr analytics/xgbpred2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'grid_scores_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-56-f581b77e5818>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m  param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n\u001b[0;32m      9\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mgsearch1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrid_scores_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgsearch1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'grid_scores_'"
     ]
    }
   ],
   "source": [
    "param_test1 = {\n",
    " 'max_depth':range(3,10,2),\n",
    " 'min_child_weight':range(1,6,2)\n",
    "}\n",
    "gsearch1 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=140, max_depth=5,\n",
    " min_child_weight=1, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    " objective= 'binary:logistic', nthread=4, scale_pos_weight=1, seed=27), \n",
    " param_grid = param_test1, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "gsearch1.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'max_depth': 3, 'min_child_weight': 1}, 0.6536800078557696)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " gsearch1.best_params_, gsearch1.best_score_\n",
    "#({'max_depth': 3, 'min_child_weight': 12}, 0.6536800078557696)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score=nan,\n",
       "             estimator=XGBClassifier(base_score=0.5, booster='gbtree',\n",
       "                                     colsample_bylevel=1, colsample_bynode=1,\n",
       "                                     colsample_bytree=0.8, gamma=0,\n",
       "                                     learning_rate=0.1, max_delta_step=0,\n",
       "                                     max_depth=3, min_child_weight=2,\n",
       "                                     missing=None, n_estimators=125, n_jobs=1,\n",
       "                                     nthread=4, objective='binary:logistic',\n",
       "                                     random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "                                     scale_pos_weight=1, seed=27, silent=None,\n",
       "                                     subsample=0.8, verbosity=1),\n",
       "             iid=False, n_jobs=4,\n",
       "             param_grid={'min_child_weight': [6, 8, 10, 12]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='roc_auc', verbose=0)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# param_test2b = {\n",
    "#  'min_child_weight':[6,8,10,12]\n",
    "# }\n",
    "# gsearch2b = GridSearchCV(estimator = XGBClassifier( learning_rate=0.1, n_estimators=125, max_depth=3,\n",
    "#  min_child_weight=2, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "#  objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "#  param_grid = param_test2b, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "# gsearch2b.fit(X,y)\n",
    "\n",
    "# gsearch2b.best_params_, gsearch2b.best_score_\n",
    "\n",
    "# param_test3 = {\n",
    "#  'gamma':[i/10.0 for i in range(0,5)]\n",
    "# }\n",
    "# gsearch3 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=125, max_depth=3,\n",
    "#  min_child_weight=12, gamma=0, subsample=0.8, colsample_bytree=0.8,\n",
    "#  objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "#  param_grid = param_test3, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "# gsearch3.fit(X,y)\n",
    "# gsearch3.best_params_, gsearch3.best_score_\n",
    "\n",
    "# param_test7 = {\n",
    "#  'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05]\n",
    "# }\n",
    "# gsearch7 = GridSearchCV(estimator = XGBClassifier( learning_rate =0.1, n_estimators=125, max_depth=3,\n",
    "#  min_child_weight=12, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "#  objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27), \n",
    "#  param_grid = param_test7, scoring='roc_auc',n_jobs=4,iid=False, cv=5)\n",
    "# gsearch7.fit(X,y)\n",
    "# gsearch7.best_params_, gsearch7.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb= XGBClassifier( learning_rate =0.1,reg_alpha=0.006, n_estimators=125, max_depth=3,\n",
    "#  min_child_weight=12, gamma=0.1, subsample=0.8, colsample_bytree=0.8,\n",
    "#  objective= 'binary:logistic', nthread=4, scale_pos_weight=1,seed=27)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit(X,y)\n",
    "y_test_pred_xgb=xgb.predict_proba(df6)[:,1]\n",
    "finalpred=pd.concat([dfte['enrollee_id'],pd.DataFrame(y_test_pred_xgb,columns=['target'])],1)\n",
    "finalpred.to_csv(\"D:/datasets+minipro/analytics vidhya datasets/janata hack p3 hr analytics/xgbpred2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
